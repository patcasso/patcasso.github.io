---
layout: single
title:  "Day 74 학습정리"
categories: boostcamp-note-week15
sidebar:
  nav: "docs"
---

24/02/15 (수) 학습 내용

<h1>MRC</h1>

<h2>(8강) Reducing Training Bias</h2>
- 강의 키워드<br><br>
: - Bias in Open-Domain Question Answering
<br><br><br>

1. Definition of Bias<br><br>
: <br><b>Bias의 종류</b><br><br>
: : Bias in Learning - 학습할 때 과적합을 막거나 사전 지식을 주입하기 위해 특정 형태의 함수를 선호하는 것 (inductive bias)
: : A Biased World - 현실 세계가 편향되어 있기 때문에 모델에 원치 않는 속성이 학습되는 것(historical bias), 성별과 직업 간 관계 등 표면적인 상관관계 때문에 원치 않는 속성이 학습되는 것(co-occurrence bias)
: : Bias in Data Generation - 입력과 출력을 정의한 방식 때문에 생기는 편향(specification bias), 데이터를 샘플링한 방식 때문에 생기는 편향 (sampling bias), 어노테이터의 특성 때문에 생기는 편향 (annotator bias)
: <br><b>Bias 예시</b><br><br>
: : <u>Gender Bias</u> - 대표적인 Bias 예시
: : <u>Sampling Bias</u> - ex) 대통령 선거 예상 : 중산층 이상으로 표본이 왜곡 (설문 대상이 잡지 정기구독자, 자동차 등록명부, 사교클럽 인명부 등을 활용했기 때문에)
<br><br><br>

2. Bias in Open-domain Question Answering<br><br>
: <br><b>Training bias in reader model</b><br><br>
: : 만약 reader 모델이 한정된 데이터셋에서만 학습이 된다면, 항상 정답이 문서 내에 포함된 데이터쌍만(Positive)보게 됨
: : Inference 시 만약 데이터 내에서 찾아볼 수 없던 새로운 문서를 준다면 독해 능력이 떨어질 것임
: <br><b>How to mitigate training bias?</b><br><br>
: : 1. Train negative examples - 훈련할 때 잘못된 예시를 보여주기
: : 2. Add no answer bias - 입력 시퀀스의 길이가 N일시, 시퀀스의 길이 외 1개의 토큰이 더 있다고 생각하기
: : 이 경우 "대답할 수 없다"로 취급
<br><br><br>

3. Annotation Bias from Datasets<br><br>
: <br><b>What is annotation bias?</b><br><br>
: : ODQA 학습 시 기존의 MRC 데이터셋 활용
: : ODQA 세팅에는 적합하지 않은 bias가 데이터 제작(annotation) 단계에서 발생할 수 있음
: : 그러나 데이터셋에서는 질문을 하는 사람이 답을 알고 있는 상태로 질문하는 편향이 생기게 된다.
: <br><b>Effect of annotation bias</b><br><br>
: : SQuAD에서 DPR의 성능 < BM25 성능인 현상이 발생한다. (Sparse가 Dense보다 더 잘 나오는 현상. 원래는 Dense가 성능이 더 잘 나오는 모델이다.)
: <br><b>Dealing with annotation bias</b><br><br>
: : Annotation 단계에서 발생할 수 있는 bias를 인지하고, 이를 고려하여 데이터를 모아야 함
: : ex) ODQA 세팅과 유사한 데이터 수집 방법 (구글의 실제 search query 활용 등)
: <br><b>Another bias in MRC dataset</b><br><br>
: : Passage가 주어지고, 주어진 passage 내에서 질문과 답을 생성
: : ODQA에 applicable 하지 않은 질문들이 존재
<br><br><br>


<h2>(9강) Closed-book QA with LLMs</h2>

1. Closed-book Question Answering<br><br>
: <br><b>Current approaches of buildling QA system</b><br><br>
: : 전통적인 MRC - 문서 내에 답변이 있다고 가정하고 질문을 던진 후 출력했음.
: : Open Domain QA - 웹상에서 직접 담을 찾아야 함
: <br><b>Idea of Closed-book Question Answering</b><br><br>
: : 모델이 이미 사전학습으로 대량의 지식을 학습했다면, 사전학습 언어모델 자체가 이미 하나의 knowledge storage라고 볼 수 있지 않을까? (ex. BERT, GPT2, BART, T5, ...)
: : 문서를 참조하지 않고, 질문을 받은 후에 바로 답을 생성하는 것
: <br><b>Evidences</b><br><br>
: : LM을 Knowledge base로 사용할 수 있지 않을까?
: : GPT-2가 사전학습 시 전혀 본 적이 없는 Natural Questions 데이터셋에도 어느 정도 대답이 가능함
: <br><b>Open-book QA vs Closed-book QA</b><br><br>
: : Closed-book QA의 경우는, 사전학습된 언어 모델이 얼마나 지식을 잘 기억하고 있는지가 매우 중요하고, 아닐 경우 Hallucination이 일어남
<br><br><br> 

2. Large Language Models and Zero-shot Performance<br><br>
: : T5를 시초로 보고, 현재는 GPT-4까지
: <br><b>Problems with Task-Specific Fine-tuning</b><br><br>
: : Labeled Data가 필요해서 비용이 큼
: : 사전학습때 학습한 General Knowledge가 손상될 위험
: : 키울 수 있는 모델의 크기가 한정적임
: <br><b>Revisit: Text-to-Text Format</b><br><br>
: : input으로 text를 받아서, output으로 새로운 text를 생성하는 문제 (프롬프팅의 시초)
: : Model Size가 모델 내부에 담을 수 있는 정보의 양과 비례한다
: <br><b>Using T5 for Closed-book QA</b><br><br>
: : 미리 학습된 pre-trained T5를 활용
: <br><b>Very Large scale Language Models</b><br><br>
: : Pretrain-Finetune의 2 step 절차 대신, in-context 정보를 통해 예측을 반환 (GPT-3, Llama)
: : 성능을 올리기 위해, instruction-tuned LLM들 등장
: : InstructGPT, Flan-T5, ChatGPT, Alpaca
: <br><b>In-context Learning</b><br><br>
: : 역전파를 통한 파라미터의 업데이터 없이, 순전파를 통해 이루어지는 학습
: : Text-to-Text Framework를 활용하여 동작
: : Task에 대한 instruction과 몇 개의 예제들을 feed-forward함
: : 사용자의 입력에 따라 다양한 형태의 Output을 산출할 수 있는 능력을 갖추게 됨.
<br><br><br>

3. LoRA Tuning<br><br>
: <br><b>Challenges with Fine-Tuning LLMs</b><br><br>
: : 모델의 크기가 커질수록 Fine-tuning이 힘들어짐
: : 적은 수의 파라미터만을 학습시키는 방법론들 대두 (LoRA)
: <br><b>LoRA</b><br><br>
: : Pre-trained weight를 고정된 상태(freeze)로 유지하며, dense layer의 변화에 대한 rank decomposition matrices를 최적화
: : 작은 rank값을 설정해도 성능을 유지
: <br><b>How to use LoRA?</b><br><br>
: : HuggingFace에서 제공하는 'peft' 라이브러리를 통해 쉽게 사용 가능
<br><br><br>

4. Experiment Result & Analysis<br><br>
: <br><b>Limitations</b><br><br>
: : 모델의 크기가 커서 계산량이 많고 속도가 느림 -> 더 효율적인 모델 필요 (ex. 온디바이스 등에서 어려움, 서버에서는 문제가 없음)
: : 모델이 어떤 데이터로 답을 내는지 알 수 없음 -> 결과의 해석 가능성 높이는 연구 필요
: : 모델이 참조하는 지식을 추가하거나 제거하기 어려움
<br><br><br>
