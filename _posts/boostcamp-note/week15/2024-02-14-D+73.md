---
layout: single
title:  "Day 73 학습정리"
categories: boostcamp-note-week15
sidebar:
  nav: "docs"
---

24/02/14 (수) 학습 내용

<h1>MRC</h1>

<h2>(6강) Passage Retrieval-Scaling Up </h2>
- 강의 키워드<br><br>
: - MIPS
: - IVF-PQ
<br><br><br>

1. Passage Retrieval and Similarity Search<br><br>
: <br><b>복습: Retrieval with dense embedding</b><br><br>
: : 이 방식의 문제는 passage의 개수가 늘어날수록 더 큰 Embedding space가 필요하다
: : Dimension이 커지면 dot product 자체도 부담스러운 연산이 될 수 있다.
: : 이 과정을 흔히 Similarity Search 라고 부른다.
: <br><b>MIPS(Maximum Inner Product Search)</b><br><br>
: : Nearest neighbor(L2 유클리드 거리 측정) 보다, Inner product search(inner product의 최대값 찾기)가 더 많이 쓰인다
: : 검색 과정에서 brute force(exhaustive search) 아닌 더 스마트한 방법에 대해 알아보자.
: <br><b>MIPS & Challenges</b><br><br>
: : 실제 검색해야 할 데이터는 훨씬 방대함
: : 위키피디아 500만 개, 검색엔진의 경우 수십억, 조 단위까지 커질 수 있음
: : -> 더이상 모든 문서 임베딩을 일일이 보며 찾을 수 없음
: <br><b>Tradeoffs of similarity search</b><br><br>
: : 1) Search speed -> Pruning
: : 2) Memory Usage -> Compression
: : 3) Accuracy -> Exhausitve search
: : 속도(search time)와 재현율(recall)의 관계 -> 더 정확한 검색을 하려면 검색 시간이 오래 걸림
: <br><b>Increasing search space by bigger corpus</b><br><br>
: : Corpus의 크기가 커질수록 검색이 어려워진다. (탐색 공간, 메모리 공간 등. Sparse Embedding의 경우 이러한 문제가 훨씬 심함)
<br><br><br>

2. Approximating Similarity Search<br><br>
: <br><b>Compression - Scalar Quantization (SQ)</b><br><br>
: : 실제 Inner product search 할 때는 4-byte까지 필요 없고, 1-byte(8bit)로 줄여서 표현해도 잘 되는 경우가 많다.
: <br><b>Pruning - Inverted File (IVF)</b><br><br>
: : Pruning - Search space를 줄여 search 속도 개선
: : Clustering + Inverted file을 활용한 search
: : 1) Clustering: 전체 vector space를 k개의 cluster로 나눔 (ex. k-means clustering)
: : 군집화를 한 후, 가까이 있는 클러스터만 방문해서 exhaustive search로 탐색하는 방법
: : 2) Inverted file (IVF)
: : Vector의 index = inverted list structure
: : 각 클러스터에 속해있는 포인트들을 역으로 인덱스로 가지고 있기 때문이다(?)
<br><br><br>

3. Introduction to FAISS<br><br>
: <br><b>What is FAISS</b><br><br>
: : 페이스북에서 만들고 모니터링하는 fast approximation을 위한 라이브러리
: : 모든 것이 오픈소스화 되어있고, large-scale에 특화되어 있다.
: : backbone은 C++로 되어있지만, wrapping은 Python으로 되어있다.
: <br><b>Passage Retrieval with FAISS</b><br><br>
: : 1) Train index and map vectors
: : 2) Search based on FAISS index
: : nprobe - 몇 개의 가장 가까운 cluster를 방문하여 search 할 것인지
<br><br><br>

4. Scaling up with FAISS<br><br>
: <br><b>FAISS Basics</b><br><br>
: : brute-force로 모든 벡터와 쿼리를 비교하는 가장 단순한 인덱스 만들기
: <br><b>IVF with FAISS</b><br><br>
: : IVF 인덱스 만들기
: : 클러스터링을 통해서 가까운 클러스터 내 벡터들만 비교함
: : 빠른 검색 가능
: : 클러스터 내에서는 여전히 전체 벡터와 거리 비교 (Flat)
: <br><b>IVF-PQ with FAISS</b><br><br>
: : 벡터 압축 기법 (PQ) 활용하기
: : 전체 벡터를 저장하지 않고 압축된 벡터만을 저장
: : 메모리 사용량을 줄일 수 있음
: <br><b>Using GPU with FAISS</b><br><br>
: : GPU의 빠른 연산 속도 활용 가능
: : 메모리 제한이나 random access 시간이 느린 것 등이 단점
: : 여러 GPU를 활용하여 연산 속도를 한층 더 높일 수 있음
<br><br><br>


<h2>(2강)</h2>
- 강의 키워드<br><br>
: - 
: - 
: - 

- 소개<br><br>
: :
: : 

- 소제목1<br><br>
: :
: : 

- 소제목2<br><br>
: :
: :
