---
layout: single
title:  "Day 75 학습정리"
categories: boostcamp-note-week15
sidebar:
  nav: "docs"
---

24/02/16 (금) 학습 내용

<h1>MRC</h1>

<h2>(10강) QA with Phrase Retrieval</h2>
- 강의 키워드<br><br>
: - Dense-Sparse Phrase
<br><br><br>

1. Phrase Retrieval in Open-Domain Question Answering<br><br>
: <br><b>Current limitation of Retriever-Reader approach</b><br><br>
: : 1) Error Propagation(에러 전파) : 5-10개의 문서만 reader에게 전달됨
: : 2) Query-dependent encoding: query에 따라 정답이 되는 answer span에 대한 encoding이 달라짐
: : Key Idea) Retrieve-Read 두 단계 말고 <u>정답을 바로 search</u> 할 수는 없을까?
: <br><b>One solution: Phrase Indexing</b><br><br>
: : Phrase들을 Key vector로 indexing 해놓고, query vector를 인코딩해 유사도를 구한다.
: : Query 벡터가 바뀌어도, key vector를 다시 구하지 않아도 되어서 효율적이다.
: : Query-Agnostic Decomposition
<br><br><br>

2. Dense-sparse Representation for Phrases<br><br>
: : Dense, sparse embedding을 같이 사용하는 것
: : Dense vectors - 통사적, 의미적 정보를 담는 데 효과적
: : Sparse vectors - 어휘적 정보를 담는 데 효과적
: : Dense vector와 sparse vector를 모두 사용하여 phrase (and question) embedding (concatenate)
: <br><b>DensePhrases</b><br><br>
: : Sparse Embedding이 더 이상 필요하지 않아졌다는 장점
: <br><b>ColBERT</b><br><br>
: : BERT 기반 랭킹 모델
<br><br><br>

3. Experiment Results & Analysis<br><br>
: <br><b>DenSPI Exp Results</b><br><br>
: : SQuAD-open에서 다른 방식들에 비해 높은 성능
: : Limitation = Retriever-reader 모델들 대비 낮은 성능
: : Decomposability gap
: <br><b>DensePhrases Experiment Results</b><br><br>
: : Retriever-Reader 모델에 비해서도 뒤떨어지지 않는 성능 + 빠른 속도
<br><br><br>