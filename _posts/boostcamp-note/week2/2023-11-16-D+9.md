---
layout: single
title:  "Day 9 학습정리"
categories: boostcamp-note-week2
sidebar:
  nav: "docs"
---

# 23/11/16 (목) 학습 내용

<h2>PyTorch</h2>

- <b>(8강) Multi-GPU 학습</b><br><br>
: <br><b>강의 키워드</b><br>
: - Model parallel
: - Data parallel
: - DistributedDataParallel
: <br><b>인트로</b><br><br>
: : 예전에는 단순한 구조에 작은 데이터로 학습할 때가 있었지만,
: : 지금은 Nvidia 등에서 좋은 GPU를 만들기 때문에, 되도록 많은 데이터를 많은 GPU에 넣어서 학습하는 방법이 일상화가 되어있다.
: : Colab은 Multi-GPU를 확보를 못 하니까, 구글 GCP 등 Multi-GPU 사용해서 학습할 수 있는 환경을 안내해주겠다.
: :  오늘날의 딥러닝은 엄청난 데이터와의 싸움
: : GPT-3는 $10^{11}$
: : Multi-GPU 어떻게 GPU를 다룰 것인가?
: <br><b>개념 정리</b><br><br>
: : Single vs. Multi (한개 vs 여러개)
: : GPU vs. Node (Node는 1대의 컴퓨터를 의미)
: : Single Node Single GPU (1대 컴퓨터의 1대 GPU를 사용한다)
: : <u>Single Node Multi GPU</u> (한 대의 컴퓨터에 여러 개의 GPU를 사용한다) => 우리가 주로 얘기하는 상황
: : Multi Node Multi GPU (예컨대 서버실에 있는 그래픽 카드들.) => 궁극적인 방향성. <u>하지만 리소스도 많이 들고 어려움이 많다.</u><br><br>
: : 다중 GPU에 학습을 분산하는 두 가지 방법은 <u>모델을 나누기 / 데이터를 나누기</u>
: <br><b>(1) Model parallel</b><br><br>
: : 모델을 병렬화 시키는 방법
: : 모델을 나누는 것은 생각보다 예전에 썼음 (ex. alexnet)
: : 모델 병렬화는 고난이도 과제(due to 모델의 병목, 파이프라인의 어려움 등)
: : 도식상에서 교차되는 부분들이 ".to('cuda:n')" 부분들
: <br><b>(2) Data parallel</b><br><br>
: : 데이터를 병렬화
: : 데이터를 나눠 GPU에 할당 후 결과의 평균을 취하는 방법
: : minibatch 수식과 유사한데 한번에 여러 GPU에서 수행하는 것
: : 두 가지 방식 DataParallel, DistributedDataParallel
: : DataParallel - 단순 데이터를 분배한 후 평균을 취함 -> GPU 사용 불균형 문제 발생, Batch 사이즈 감소 (한 GPU가 병목), GIL(Global Interpreter Lock) 문제
: : DistributedDataParallel - 각 CPU마다 process 생성하여 개별 GPU에 할당 -> 기본적으로 DataParallel로 하나씩 개별적으로 연산의 평균을 냄
: : DistributedDataParallel을 사용하려면 Sampler를 사용해 정의한 후 DataLoader에서 sampler에 지정해 주어야 한다.
: : num_workers는 보통 GPU $\times 4$ 를 하라고 한다.
: : 본 강의에서는 실습을 하지 못했지만, AWS, GCP, NaverCloud 등에서 이런 코드들을 돌려볼 것을 권장한다.
: : Colab에서는 쓸 일이 없지만, 미래를 위해 익혀두자!!



- <b>(9강) Hyperparameter Tuning</b><br><br>
: <br><b>키워드</b><br>
: - Hyperparameter Optimization
: - Grid Search
: - Random Search
: <br><b>인트로</b><br><br>
: : 하이퍼파라미터의 예 : 학습률, 감쇄율 등
: : 예전에는'손맛'으로 hyperparameter 튜닝을 했으나, 요즘은 좋은 도구들이 많이 나왔다.
: <br><b>Hyperparameter Tuning</b><br><br>
: : 가장 좋은 성능을 내는 데 중요한 것은 '**데이터**'이다. 왜냐하면 모델의 영향이 가장 크긴 하지만, 모델은 어느 정도 최적화 된 것들이 정해져있기 때문이다. (ex. NLP에서는 Transformer)
: : 데이터는 다다익선!
: : Hyperparameter Tuning으로 얻어지는 메리트는 그렇게 크지는 않음 (마지막 0.01을 쥐어짜야 할 때 도전해볼만!)
: : 모델 스스로 학습하지 않는 값은 사람이 지정(ex.learning rate (=> NAS 방법이라는 것 참조해보기), 모델의 크기, optimizer 등)
: : 하이퍼 파라메터에 의해 값이 크게 좌우될 때도 있었다(요즘은 그다지..) Ex. Google's recipe<br><br>
: : 가장 기본적인 방법 - grid vs random
: : Grid Layout-> 0.1, 0.01, 0.001 등으로 로그를 취한 값을 점점 올려주는 방법
: : It's called <u>Grid Search</u>
: : Random Layout -> 랜덤하게 아무 값이나 넣어서 잘 나오는 값을 찾아주는 것
<br><br>
: : 최근에는 베이지안 기반 기법들이 주도 (대표적인 논문으로 BOHB, Bayesian Optimization HyperBand)
: <br><b>Ray</b><br><br>
: : multi-node multi processing 지원 모듈
: : ML/DL 병렬 처리를 위해 개발된 모듈
: : 현재의 분산병렬 ML/DL 모듈의 표준
: : Python의 일반적인 병렬 처리도 Ray에게 맡기는 추세이다
<br><br>
: : config에 search space 지정
: <br><b>정리</b><br><br>
: : 하이퍼파라미터 튜닝에 너무 목숨걸지 마라
: : 시간 대비 효과가 많이 떨어진다.

- <b>(10강) PyTorch Troubleshooting</b><br><br>
: <br><b>키워드</b><br>
: - GPU Memory Management
: - torch.cuda.empty_cache()
: - Handling Accumulating Tensors
: - Dynamic Batch Sizing
: <br><b>인트로</b><br><br>
: : 학습할 때 자주 마주칠 수 있는 문제들에 대해 정리
: <br><b>OOM (Out Of Memory)</b><br><br>
: : 학습을 하면서 많이 마주치는 문제<br><br>
: : <u>해결하기 어려운 이유들</u>
: : 왜 발생했는지 알기 어려움
: : 어디서 발생했는지 알기 어려움
: : Error backtracking이 이상한데로 감
: : 메모리의 이전 상황의 파악이 어려움<br><br>
: : 해결 방법들) <br><br>
: : Batch Size ↓ -> GPU clean -> Run
: : (Colab의 경우 커널을 clear)
: <br><b>\<그 외에 발생할 수 있는 문제들></b><br>
: <br><b>GPU Util 사용하기</b><br><br>
: : nvidia-smi처럼 GPU의 상태를 보여주는 모듈
: : Colab은 환경에서 GPU 상태 보여주기 편함
: : iter마다 메모리가 늘어나는지 확인
: : !pip install GPUtil 로 설치
: <br><b>torch.cuda.empty_cache() 써보기</b><br><br>
: : 사용되지 않은 CPU상 cache를 정리
: : 가용 메모리를 확보
: : del과는 구분이 필요
: : reset 대신 쓰기 좋은 함수
: <br><b>training loop에 tensor로 축적되는 변수는 확인할 것</b><br><br>
: : tensor로 처리된 변수는 GPU상에 메모리 사용
: : 해당 변수 loop 안에 연산이 있을 때 GPU에 computational graph를 생성(메모리 잠식)
: : 1-d tensor의 경우 python 기본 객체로 변환하여 처리할 것 (.item 함수, float() 함수 처리)
: <br><b>del 명령어를 적절히 사용하기</b><br><br>
: : 필요가 없어진 변수는 적절한 삭제가 필요
: : python 메모리 배치 특성상, loop이 끝나도 메모리를 차지함
: <br><b>가능 batch 사이즈 실험해보기</b><br><br>
: : 학습시 OOM이 발생했다면 batch 사이즈를 1로 해서 실험해보기
: <br><b>torch.no_grad() 사용하기</b><br><br>
: : <a href="https://wikidocs.net/120169">Inference</a> 시점에서는 torch.no_grad() 구문을 사용
: : backward pass 으로 인해 쌓이는 메모리에서 자유로움
: <br><b>예상치 못한 에러 메시지</b><br><br>
: : OOM 말고도 유사한 에러들이 발생
: : CUDNN_STATUS_NOT_INIT이나 device-side-assert 등
: : 해당 에러도 cuda와 관련하여 OOM의 일종으로 생각될 수 있으며, 적절한 코드 처리 필요
: <br><b>그 외</b><br><br>
: : colab에서 너무 큰 사이즈는 실행하지 말 것 (linear, CNN, <span style="color:red">LSTM</span>)
: : CNN의 대부분의 에러는 크기가 안 맞아서 생기는 경우 (torchsummary 등으로 사이즈를 맞출 것)
: : tensor의 float precision을 16bit로 줄일 수도 있음

<h2>과제 및 퀴즈 수행 내용</h2>
- (퀴즈) PyTorch 완성하기<br><br>
: : <u>9번 문제 복습 필요</u>
: : "optimizer.step()" 함수가 축적된 그래디언트를 사용하여 모델의 가중치를 업데이트하는 함수라는 사실을 잘 이해하지 못하고 있었다.
: : 딥러닝 모델에서 왜 optimizer.zero_grad(), loss.backward(), optimizer.step() 의 순서로 나오는지 이제 알 것 같다. 먼저 그래디언트 값을 초기화 해주고, 손실함수에 대한 미분을 진행해 기울기를 구해준 후, 마지막으로 이를 이용하여 가중치를 업데이트 해주는 과정이었던 것이다. 
- 기본 과제 2
: : AG_News 관련 문제에서 많이 막힘. 해당 개념을 잘 복습해놓자.


<h2>Peer Session</h2>
<br><b>기본 과제 2 토론</b><br><br>
: : 마지막 AG_News 문제에서 인코딩 안 되는 단어들 에러 처리 방식.. 괜찮은 걸까? (스샷 있음)
