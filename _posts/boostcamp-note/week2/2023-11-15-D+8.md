---
layout: single
title:  "Day 8 학습정리"
categories: boostcamp-note-week2
sidebar:
  nav: "docs"
---

# 23/11/15 (수) 학습 내용

<h2>PyTorch</h2>

- <b>(6강) 모델 불러오기</b><br><br>
: <br><b>강의 키워드</b><br>
: - Model Saving
: - Model Loading
: - Checkpoint
: - Transfer Learning
: <br><b>소개</b><br><br>
: : 최근 AI 쪽에서는 Backbone 이라는 기본적인 모델이 있고 (특정 타겟에 학습이 되어있는), 나의 데이터에 맞춰 Fine-tuning 하는 방식이 대세가 되고 있다.
: : NLP 쪽에서는 트랜스포머 기반의 BERT 모델이 대세로 자리잡으면서, 이미 학습된 모델을 가져와 나의 타겟에 특화시키는 방법이 일상화 되어있고,
: : 이를 <u>Transfer Learning</u>이라고 한다! (매우 중요할듯)
: : 그러기 위해서는 기본적인 모델의 구조를 어느정도 알아야 한다.
: : 특히 Image Classification 같이 우리가 정복했다고 생각하는 분야들에서는 좋은 성과를 낼 수 있다.
: <br><b>학습 결과를 공유하고 싶다</b><br><br>
: : 학습 결과를 저장해야 한다.
: : (Colab Pro 쓰면 안 끊긴다..)
: <br><b>model.save()</b><br><br>
: : 학습의 결과를 저장하기 위한 함수
: : 모델의 형태(architecture)와 파라미터(parameter)를 저장
: : 모델의 중간 결과들을 저장(ex. for Early stopping)
: : 만들어진 모델을 외부 연구자와 공유하기 위해
: : state_dict() : 모델의 파라미터를 표시
: : 모델을 저장할 때는 ordered dict를 사용한다.
: : PT에서 모델을 저장할때는 pt라는 확장자 많이 사용
: : 같은 모델의 형태에서 파라메터만 load (load_state_dict)
: <br><b>checkpoints</b><br><br>
: : 학습의 중간 결과를 저장하여 최선의 결과를 선택
: : earlystopping 기법 사용시 이전 학습 결과물 저장
: : 일반적으로 epoch, loss, metric을 함께 저장하여 확인<br><br>
: **cuda 란?**
: : Compute Unified Device Architecture[1]
: : NVIDIA가 만든 GPGPU 플랫폼 및 API 모델이다.
: : CUDA 플랫폼은 GPU의 가상 명령어셋을 사용할 수 있도록 만들어주는 소프트웨어 레이어이며, NVIDIA가 만든 CUDA 코어가 장착된 GPU에서 작동한다.
: : <a href="https://namu.wiki/w/CUDA">나무위키</a>
: <br><b>Transfer learning</b><br><br>
: : 남이 만든 모델을 쓰고 싶다!
: : 다른 데이터셋으로 만든 모델을 현재 데이터에 적용 (ex. ImageNet)
: : 일반적으로 대용량 데이터셋으로 만들어진 모델의 성능이 좋다
: : 현재의 DL에서는 가장 일반적인 학습 기법
: : TorchVision은 다양한 기본 모델 제공
: : NLP에서는 HuggingFace가 표준 (<a href="https://huggingface.co/models">링크</a>)
: <br><b>Freezing</b><br><br>
: : pretrained 모델 활용시 모델의 일부분을 freeze 시킴
: : 일부 레이어에서만 Backpropagation이 일어나게 하는 방법
: : pretrained 모델은 freeze 시켜주고, 마지막에 추가한 선형 모델의 parameter만 학습시키는 방식으로 구현해야 한다.<br><br><br>


- <b>(7강) Monitoring tools for PyTorch</b><br><br>
: <br><b>키워드</b><br>
: - WandB 모니터링 도구
: - PyTorch TensorBoard
: - PyTorch Lightning Logger 목록들
: <br><b>인트로</b><br><br>
: : 긴 학습 시간... 기다림의 기록이 필요
: : 가장 쉬운 방법은 print문을 쓰는 것. log나 csv도...
: : But! 좋은 도구들이 많다.
: : Tensorboard, weight & biases (WandB)
: : print문 이외의 방법에 익숙해지기
: <br><b>Tensorboard</b><br><br>
: : TensorFlow의 프로젝트로 만들어진 시각화 도구
: : 학습 그래프, metric, 학습 결과의 시각화 지원
: : PyTorch도 연결 가능 -> DL 시각화 핵심 도구<br><br>
: : - 모니터링 가능한 것들
: : scalar : metric(ACC, Loss, Precision, Recall, ...)등 상수 값의 연속(epoch)을 표시
: : 시간(epoch)에 따른 그래프로 표시
: : histogram :  weight등 값의 분표를 표현 (정규분포로 표현되는 것이 좋다?)
: : mesh : 3d 형태의 데이터를 표현하는 도구<br><br>
: : - 과정
: : 기록을 위한 directory 생성
: : 주로 weight 값들을 조정할 때 히스토그램 많이 쓴다
: : 실습 코드 참조
: <br><b>weight & biases</b><br><br>
: : 머신러닝 실험을 원활히 지원하기 위한 상용도구 (기본 기능은 무료로도 사용 가능)
: : 협업, code versioning, 실험 결과 기록 등 제공
: : MLOps의 대표적인 툴로 저변 확대중
: : wandb.ai에 github 회원가입 후 API key를 통해 연동하면, 나의 실험 결과를 사이트에 저장해주는 도구이다.
: : 실험을 공유하거나 할 때 굉장히 편한 도구이다.
: : 즉, TensorBoard에서 제공하는 기능들을 WandB 에서도 거의 동일하게 제공해준다는 것을 기억하면 된다.
: <br><b>정리</b><br><br>
: : 이러한 로깅을 지원하는 다양한 도구들을 활용해보는 것이 중요하다.
: : 회사에서 일할 때, 나의 회사를 차릴 때 등 이런 새로운 도구들을 늘 도전해 보는 자세를 갖자.


<h2>과제 수행 내용</h2>
- 기본 과제 2


<h2>Peer Session</h2>
<br><b>기본 과제 2 토론</b><br><br>
: <br><b>hook</b><br><br>
: : hook에 여러 종류가 있는데 어떤 차이?
