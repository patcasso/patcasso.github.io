---
layout: single
title:  "Day 37 학습정리"
categories: boostcamp-note-week8
sidebar:
  nav: "docs"
---

23/12/27 (수) 학습 내용

<h1>AI 서비스 개발 기초</h1>

<h2>(4강) Docker 입문</h2>
- 강의 키워드<br><br>
: - 컨테이너화(Containerization)
: - 이미지 및 컨테이너 관리(Image and Container Management)
: - 도커(Docker) 기초
<br><br>

- Docker 소개<br><br>
: <br><b>가상화란?</b><br><br>
: : 개발할 때, 서비스 운영에 사용하는 서버에 직접 들어가서 개발하지 않음
: : Local 환경에서 개발하고, 완료되면 Staging 서버, Production 서버에 배포
: : 개발 진행한 Local 환경과 Production 서버 환경이 다른 경우 (ex. 로컬은 맥, 프로덕션은 리눅스)
: : OS가 다르기 때문에 라이브러리, 파이썬 등 설치할 때 다르게 해야 함
: : Local의 환경 변수, Production 서버의 환경 변수(Env)가 겹치거나 꼬일 수 있음
: : 사용자 그룹, Permission이 다를 수 있음
: : ex) 운영하고 있는 서버가 100대라면? => 특정 서버 업데이트가 진행되었다면 나머지 서버도 모두 업데이트 해야 함
<br><br>
: : 고민 -> 서버 환경까지도 모두 한번에 소프트웨어화 할 수 없을까?
: : 이를 해결하기 위해 나온 개념이 "가상화" (여기서는 소프트웨어 가상화)
: : Research / Production 환경에서 공통적으로 사용하는 일종의 템플릿
: <br><b>Docker 등장하기 전</b><br><br>
: : 주로 VM(Virtual Machine)을 사용
: : 호스트 머신이라고 하는 실제 물리적 컴퓨터 위에, OS를 포함한 가상화 소프트웨어를 두는 방식
: : OS를 포함하기 때문에, 조금 무겁다는 이슈가 있었음
: : GCP의 Compute Engine, 또는 AWS EC2가 이런 개념을 활용
: : Container : VM의 무거움을 크게 덜어주면서, 가상화를 좀 더 경량화된 프로세스의 개념으로 만든 기술
: <br><b>Docker 소개</b><br><br>
: : Container 기술을 쉽게 사용할 수 있도록 나온 도구가 바로 Docker
<br><br>
: : <u>Docker Image</u>
: : 컨테이너를 실행할 때 사용할 수 있는 템플릿
: : Read Only
<br><br>
: : <u>Docker Container</u>
: : Docker Image를 활용해 실행된 인스턴스
: : Write 가능
: <br><b>Docker로 할 수 있는 일</b><br><br>
: : 다른 사람이 만든 소프트웨어를 가져와서 바로 사용 가능 (ex. MySQL, Jupyter Notebook을 Docker로 실행)
: : 다른 사람이 만든 소프트웨어 -> Docker Image
: : OS, 설정을 포함한 실행 환경
: : Linux, Windows, Mac 어디서나 동일하게 실행 가능
: : 자신만의 이미지를 만들면 다른 사람에게 공유 가능
: : 원격 저장소 -> Container Registry
: : 회사에서 서비스를 배포할 때는 원격 저장소에 이미지를 업로드하고, 서버에서 받아서 실행하는 식으로 진행
: : dockerhub, GCR, ECR 등
<br><br>

- Docker 실습<br><br>
: <br><b>설치하고 실행하기</b><br><br>
: : docker run 할 때 파일 공유하는 방법
: : <u>Volume Mount</u>
: : 만약 파일을 유지하고 싶다면, Host와 Container의 저장소를 공유해야 함
: : -v 옵션을 사용하며, -p처럼 사용함 (-v Host_Folder:Container_Folder)
: : ex) docker run -it -p 8888:8888 -v /some/host/folder/for/work:/home/jovyan/workspace/jupyter/minimal-notebook
<br><br>
: : dockerhub에서 공개된 모든 이미지를 다운받을 수 있음
: : MySQL도 Dockerhub에서 다운로드
: : 웬만한 오픈소스들이 공개되어 있고, 필요한 이미지를 찾아 실행하는 것
: <br><b>Docker Image 만들기</b><br><br>
: : 보통 처음부터 만들지 않고, 이미 공개된 이미지를 기반으로 새로운 설정 추가
: : 실제 사용할 때 강의자료 참고해서 해보기
: <br><b>Registry에 Docker Image Push</b><br><br>
: : 본 강의에서는 Dockerhub 사용


<h2>(5강) 디버깅 Case Study</h2>
- 강의 키워드<br><br>
: - 디버깅 기술(Debugging Techniques)
: - 문제 해결 및 오류 분석(Problem Solving & Error Analysis)

- 개발 과정의 디버깅<br><br>
: <br><b>디버깅이란?</b><br><br>
: : 오류나 버그를 찾고 수정하는 과정
: : 사람의 실수, 실행 환경, 의존성, 복잡성, 커뮤니케이션 과정의 실수 등으로 인해 발생할 수 있다.
: <br><b>디버깅 Process</b><br><br>
: : 1) 문제 발생
: : 2) 문제 인식 : 문제 상황 확인, 어떤 상황인가? 재현이 되는가?
: : 오류 분류하기 - 어떤 오류인가? 오류 메시지 읽기 (코드 오류, 인프라 오류, 알 수 없는 오류 등)
: : 3) 해결책 찾기
: : 과거에 경험한 문제인가? -> 오답 노트를 찾아본다
: : 아니면, 해결책 검색 시작 (구글, Stackoverflow, 오픈카톡방, 공식 문서, Github Issue, ChatGPT) -> 오픈소스라면 코드 확인
: : 기록 - 오답노트 (블로그 등에 기록해놓는다. 나의 경우 워드로 만들어놓은 파일을 블로그에 카테고리별로 정리해서 올려보자.)
<br><br>
: : 무엇이 문제인지 아는 것이 중요
: : 실행 환경 - OS, 가상환경 여부, 사용하는 라이브러리 버전
: : 재현 가능하도록 준비해야 누군가에게 질문 가능
: : 오류 메시지를 꼭 잘 읽기. 그냥 넘어가는 것이 아닌 제대로 읽어보기.
: : ChatGPT는 100% 정답을 내지 않는 것을 인지하고 사용해야 한다.
<br><br>
: : 마스터님의 실제 디버깅 과정 보며 따라가기
<br><br>

- 서버 관리 Case Study<br><br>
: <br><b>서버 관리</b><br><br>
: : AI, ML 엔지니어가 만든 모델은 대부분 서버에서 동작
: : 서버를 어떻게 관리할 수 있는지를 배울 필요 있음
: : 깊은 서버 관리가 아닌 간단한 서버 관리 다루며, 스스로 문제를 파악하는 디버깅 과정과 유사
: : 서버 관리의 목적은 서버를 안정적으로 운영해서 장애를 발생하지 않기 위함
: <br><b>파일 시스템, 디스크 용량</b><br><br>
: : Linux 파일 시스템 구성 (강의자료 참조)
: : bin, boot, opt, dev, home, lib 등
: : Linux도 잔여 디스크 용량이 속도에 영향을 미친다
: : df -h (파티션 단위 확인), du -h -d2 (폴더별로 확인) 
: : (-h는 Human-readable의 약자로, 사람이 보기 좋게 출력)
<br><br>
: Error: No space left on device
: : 원인 - 해당 머신에 남은 공간이 부족할 때
: : 사용하지 않는 파일들을 지워주되, 파일별로 확인하고 삭제
: : 서버가 어떤 환경에서 실행 중인지 확인 필요
<br><br>
: Error: No such file or directory
: : 원인 - 찾으려고 하는 파일이나 경로가 없을 때
: : 파일의 경로, 실제 존재 여부 등 확인
<br><br>
: <br><b>네트워크</b><br><br>
: : IP : 네트워크에 연결된 다른 컴퓨터의 주소
: : 16.144.223.21 같이 숫자로 설정
: : IP 주소는 어려우니 도메인을 구매해서 설정
: : DNS : 사람이 읽을 수 있는 도메인 이름 (예.www.amazon.com)을 컴퓨터가 읽을 수 있는 IP 주소(예: 192.0.2.44)로 변환
: : Port
: : 포트 숫자는 PC에 접속할 수 있는 통로
: : 예: localhost:8000, 8000번 포트로 접속
: : 포트를 개방해야 사용할 수 있음
<br><br>
: : 방화벽
: : 필수는 아니지만, OS에 특정 IP, Port만 접속할 수 있도록 설정
: : 보통 이런 IP, Port를 ACL(Access Control List) 혹은 White List라고 부름
: : ping
: : 서버가 연결되어 있는지, 얼마나 빠른 속도로 데이터가 전송되는지 테스트
: : 네트워크 상에서 서버에게 작은 패킷을 보내고, 서버가 이를 받았다는 신호를 받는 것으로 동작
: : ping + IP 주소나 도메인 이름을 입력함
: : ex) ping google.com
<br><br>
: : Error: 서버에 Jupyter Notebook을 실행했는데 웹에서 접속할 수 없는 경우
: : 원인 : 웹에서 접근이 되지 않음
: : 해결 방법
: : IP 주소 잘 작성했는지 확인
: : 네트워크 연결 확인 (ping, netstat으로 포트 확인)
: : Jupyter Notebook 실행시 해당 IP로 실행했는지 확인
: : 방화벽 확인
: : 로그 확인
: : 서버 과부하 여부를 확인
: : 디스크 용량이 가득 차서 오류가 발생할 수 있음
: : Docker 사용할 경우 Log파일이 자동으로 생성되어서 쌓이곤 하는데, 이것 때문에 용량이 가득 찰 수도 있다.
: : FastAPI 사용해 웹서버 만들었다면 여러 이유가 있을 수 있음(인프라 영역, DB, 프론트 등) -> 디버깅하며 하나씩 해결
: <br><b>성능 확인</b><br><br>
: : GPU, CPU, Memory의 성능을 확인하고 싶은 경우
: : AI 모델 학습 과정에서 사용하고 있는 리소스를 확인해야 할 수 있음 (너무 많이 사용하고 있다면 다른 작업 추가적으로 할 수 없으므로)
: : top이란 명령어로 확인 가능 (CPU, Memory)
: : glances, nvidia-smi도 GPU 사용량 확인 가능

<h2>(6강) MLOps 개론</h2>

- 강의 키워드<br><br>
: - 머신 러닝 운영(Machine Learning Operations)
: - 지속적 통합 및 배포(Continuous Integration and Deployment)
: - 모델 모니터링 및 유지보수(Model Monitoring & Maintenance)
<br><br>

- MLOps 개론<br><br>
: <br><b>모델 개발 프로세스(Research)</b><br><br>
: : 문제 정의 -> EDA -> Feature Engineering -> Train -> Predict
: : 위 프로세스는 보통 자신의 컴퓨터, 서버 인스턴스 등에서 실행
: : 고정된 데이터를 사용해 학습
: : 학습된 모델을 앱, 웹 서비스에서 사용할 수 있도록 만드는 과정이 필요
: <br><b>모델 개발 프로세스(Production)</b><br><br>
: : 문제 정의 -> EDA -> Feature Engineering -> Train -> Predict -> Deploy
: : 모델이 배포되었다고 가정
<br><br>
<u>모델의 결과값이 이상한 경우가 존재</u>
: : 원인 파악 필요
: : Input 데이터가 이상한 경우가 존재
: : Research 할 땐 Outlier로 제외할 수 있지만, 실제 서비스에선 별도 처리 필요
<br><br>
<u>모델의 성능이 계속 변경</u>
: : 예측 값과 실제 레이블을 알아야 모델 성능 확인 가능
: : 정형(Tabular) 데이터에서는 정확히 알 수 있지만, 비정형 데이터(이미지 등)는 잘 모를 수 있음
<br><br>
<u>새로운 모델이 더 안 좋다면?</u>
: : 이전 모델이 더 좋았다면, 다시 사용하기 위한 작업이 필요
<br><br>
: : 머신러닝 모델링 코드는 머신러닝 시스템 중 일부에 불과함
: : MLOps = ML (Machine Learning) + Ops (Operations)
: : 머신러닝 모델을 운영하면서 반복적으로 필요한 업무를 자동화시키는 과정
: : 머신러닝 엔지니어링 + 데이터 엔지니어링 + 클라우드 + 인프라
: : 최근엔 비즈니스 문제에 ML/DL 적용하는 Case 많아짐
: : Production 환경에 배포하는 과정엔 Research 모델이 재현 가능해야 함 + 현실의 Risk 있는 환경에서 잘 버틸 수 있어야 함
: : MLOps의 목표는 빠른 시간 내에 가장 적은 위험을 부담하며 아이디어 단계부터 Production 단계까지 ML 프로젝트를 진행할 수 있도록 기술적 마찰을 줄이는 것
<br><br>
<u>Research와 Production의 차이</u>
: : 강의자료 도표 참조
<br><br>
<u>요즘 MLOps</u>
: : 요즘 MLOps는 춘추 전국 시대. 딱 정해진 하나의 라이브러리가 있진 않고, 클라우드에서도 서비스 경쟁중
: : 라이브러리에 집중하기보다는, 방법론을 공부하자
<br><br>

- MLOps Component<br><br>
: <br><b>Infra(Server, GPU)</b><br><br>
: : 클라우드 - AWS, GCP, Azure, NCP 등
: : 온 프레미스 - 회사나 대학원의 전산실에 서버를 직접 설치
: <br><b>Serving</b><br><br>
: : Batch Serving - 많은 데이터를 일정 주기(1일, 1주, 1달 등)로 한꺼번에 예측
: : Online Serving - 한 번에 하나씩 실시간으로 예측. 동시에 여러 request가 들어올 경우 병목이 없어야 하고, 확장 가능하도록 준비해야 함.
: <br><b>Experiment, Model Management</b><br><br>
: : 가장 성능이 좋았던 모델을 production에 넣게 됨
: : 모델 Artifact, 이미지 등
: : 모델 생성일, 모델 성능, 모델 메타 정보 등을 기록해둘 수 있음
: : 오픈소스 중 가장 유명한 것 - mlflow
: <br><b>Feature Store</b><br><br>
: : ex) FEAST 라는 라이브러리
: : Feature Store 두, 세개 라이브러리 중 하나
: <br><b>Data Validation</b><br><br>
: : 학습시와, Production에서의 데이터 분포가 달라질 수 있음
: : Static models vs Refreshed models
: : ex) TFDV(Tensorflow Data Validation)
: : ex) AWS Deequ : Unit Test for data, Data Quality 측정
: <br><b>Continuous Training</b><br><br>
: : 새로운 데이터가 들어왔을 때 / 일정 주기로 / Metric 기반 / 요청시 다시 Training 할 수 있음
: <br><b>Monitoring</b><br><br>
: : 모델의 지표, 인프라의 성능 지표 등을 잘 기록해야 할 필요성이 있음
: <br><b>AutoML</b><br><br>
: : MS의 NNI라는 서비스가 있음
: <br><b>정리</b><br><br>
: : 머신러닝 모델을 직접 운영하면서 신경써야 하는 부분
<br><br>
: <a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning?hl=ko">MLOps: 머신러닝의 지속적 배포 및 자동화 파이프라인</a> : Google에서 작성한 MLOps 내용