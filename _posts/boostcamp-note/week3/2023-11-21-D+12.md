---
layout: single
title:  "Day 12 학습정리"
categories: boostcamp-note-week3
sidebar:
  nav: "docs"
---

# 23/11/21 (화) 학습 내용

<h2>DL Basics</h2>

- (4강) Convolutional Neural Networks<br><br>
: <br><b>강의 키워드</b><br><br>
: - Convolutional Neural Networks
: - Pooling
: - Feature Maps
: - Image Classification
: <br><b>Convolution</b><br><br>
: : kernel과 이미지의 convolution에서의 연산은 행렬곱이 아닌 성분곱의 합인 것에 주의
: <br><b>Stack of Convolutions</b><br><br>
: : Convolution을 한 번 거친 후에, 각 element별로 activation (ex. ReLU) 을 거치는 형태의 Convolution Layer가 stack된다
: : Output layer의 dimension(채널)이 n이 되게 하려면, n개의 convolution filter가 필요하다.
: <br><b>Convolutional Neural Networks</b><br><br>
: : Convolution and pooling layers: feature extraction
: : Fully connected layer: decision making
: : 점점 Fully connected layer를 없애거나 작게 하는 추세라고 한다. (파라미터 수를 줄여야 generalization 이 잘 되어서)
: <br><b>Stride & Padding</b><br><br>
: : Convolution filter를 얼마나 sparse/dense하게 찍을 것인가
: : 2차원의 경우 (2,2) stride 같이 두 개의 값을 가진다.
: : 0 padding을 통해 가장자리에 패딩 추가
: <br><b>Convolution Arithmetic</b><br><br>
: : Padding(1), Stride(1), 3*3 Kernel
: : Input : W: 40, H: 50, C: 128
: : Output : W:40, H: 50, C: 64
: : 이 모델을 정의하기 위한 parameter 개수는?
: : $3 \times 3 \times 128 \times 64 = 73,728$
: : 3 x 3 x 128짜리 커널이 64개(아웃풋 레이어의 채널 수) 만큼 필요하니까!
: : Padding, Stride 등은 parameter 수와는 관계 없고, parameter 수는 오직 Kernel(혹은 filter)이 몇 개인지에 따라 결정된다.
: <br><b>AlexNet 파라미터 개수 계산하기</b><br><br>
: : 첫 번째 레이어 = (11 * 11 * 3 * 48) * 2(GPU 메모리 한계상 2개의 네트워크로 되어있음) ~ 35k
: : 두 번째 레이어 = (5 * 5 * 48 * 128) * 2 ~ 307k
: : 세 번째 레이어 = (3 * 3 * 128 * 2 * 192) * 2 ~ 884k
: : 네 번째 레이어 = (3 * 3 * 192 * 192) * 2 ~ 663k
: : 다섯 번째 레이어 = (3 * 3 * 192 * 128) * 2 ~ 442k
: : 여섯 번째 레이어(Dense, Fully connected 레이어) = (13 * 13 * 128 * 2) * 2048 * 2 ~ 177M
: :  번째 레이어(Dense, Fully connected 레이어) = (2048 * 2 * 2048 * 2) ~ 16M
: : 마지막 레이어 = 2048 * 2 * 1000 ~ 4M
: : NN 성능을 올리기 위해서는 Parameter수를 줄여야 하는데, 위와 같이 뒷단의 Fully Connected에서 많이 늘어나므로 앞단의 Convolution을 깊게 쌓고, 뒷단을 적게 하는 것이 추세인 것이다.
: <br><b>1x1 Convolution</b><br><br>
: : 이미지에서 한 픽셀만 보는 것
: : Dimension reduction (Channel을 의미)
: : NN을 더 깊게 쌓으면서 parameter 수는 줄이는 테크닉(e.g., bottleneck architecture)
: <br><b>4강 실습</b><br><br>
: : <a href="https://hobinjeong.medium.com/cnn%EC%97%90%EC%84%9C-pooling%EC%9D%B4%EB%9E%80-c4e01aa83c83">Max Pooling 설명글</a>
: : <a href="https://kau-deeperent.tistory.com/142" style="color:red">Convolution은 왜 사용하고, CNN이 왜 잘 되는 걸까?</a>
: : <a href="https://velog.io/@yeonheedong/DL-CNN-%ED%8A%B9%EC%A7%95-%EC%B6%94%EC%B6%9C-%EA%B3%BC%EC%A0%95" style="color:red">CNN 특징 추출 과정</a>
: : <a href="https://chat.openai.com/share/e5bf4de8-0f86-4bb3-8970-db401f09ed58">CNN이 어떻게 각 레이어에서 간단한 특징에서 시작해서 점점 복잡한 특징을 추출하는지에 대한 ChatGPT의 설명</a>
: <br><b>4강 퀴즈 틀린 문제</b><br><br>
: Q. CNN에서 여러 채널을 사용하는 주된 이유는 무엇인가요?
: A. 다양한 공간적 특징을 동시에 학습 (여러 채널을 사용하면 다양한 공간적 특징을 동시에 학습하여 모델의 성능을 향상시킬 수 있습니다.)

- (5강) Modern CNN<br><br>
: <br><b>강의 키워드</b><br><br>
: - ResNet, GoogLeNet, AlexNet, VGGNet, DenseNet
: <br><b>소개</b><br><br>
: : 그렇게 Modern은 아니다.. (기껏해야 2018 까지임)
: : 진짜 Modern한 네트워크는 도메인별 수업에서~
: : ILSVRC(ImageNet Large-Scale Visual Recognition Challenge) 해마다 1등 했던 모델들을 볼 것임
: : 결론적으로, depth 는 점점 깊어지고 parameter는 점점 줄어들고 성능은 올라가고의 방향!
: <br><b>AlexNet</b><br><br>
: : Input이 11*11 feature를 사용하는데, 그렇게 좋은 선택이 아니다. 하나의 Convolutional Kernal이 볼 수 있는 영역은 커지지만, Parameter 수가 많이 늘어나게 된다.
: : 총 8개의 Layer로 되어있는 NN (요즘은 100, 200, 300단 까지..)
: : 성공 이유들
: - ReLU를 사용함
<br>: 기존의 sigmoid, tanh는 vanishing gradient 문제가 있다
: - GPU를 사용함 (2 GPUs)
: - Local response normalization (지금은 많이 활용 x), Overlapping pooling
: - Data augmentation
: - Dropout
: : 지금은 다 당연하게 사용하는 것들인데, 그때는 당연하지 않았음. 지금의 기준을 잡아준 것.
: <br><b>VGGNet</b><br><br>
: : 3 x 3 Convolution filter들을 사용해 depth를 늘렸다
: : 왜 3 x 3일까?
: : 필터의 사이즈가 클 때의 이점은 고려되는 Input의 크기(Receptive Field)가 커진다는 것인데,
: : 3 x 3 Conv. 를 두 번 했다고 해보면, Receptive Field는 5 x 5가 된다.
: : 하지만 3 x 3 두 layer와 5 x 5 한 layer의 parameter 개수는 꽤 많이 차이가 난다 (약 1.5배로 3 x 3 이 더 적다).
: : 요즘은 거의 7 x 7은 넘지 않는다고 한다.
: <br><b>GoogLeNet</b><br><br>
: : 총 22개의 Layer로 되어있다.
: : 비슷하게 보이는 네트워크가 반복되는데, 이를 Network in Network(NiN) 구조라고 한다.
: : Inception Block은 하나의 입력이 들어왔을 때, 여러개로 퍼졌다가 하나로 합쳐지게 되는 것.
: : Conv 필터에 들어가기 전에 1x1 Conv이 들어가는데, 이게 중요하다.
: : 전체적인 네트워크의 parameter를 줄이게 된다.
: : How?
<br><br>
: : 1x1 conv. can be seen as channel-wise dimension reduction.
: : 채널 수를 줄이는 것.
: : <span style="color:red">Q. 그럼 다양한 특징을 학습하는 데 기능이 저하되지는 않는지?</span>
<br><br>
: : Alexnet (8-layers) - 60M parameters
: : VGGNet (19-lyaers) - 110M parameters
: : GoogLeNet (22-layers) - 4M
: : 성능은 점점 좋아짐
: <br><b>ResNet</b><br><br>
: : 그 유명한 Kaiming He의 논문
: : Deep networks are hard to train
: : Overfitting is usually caused by an excessive number of parameters
: : Add an identity map
: : skip connection : $f(x) \to x + f(x)$
: : This opened up the possibility to stack networks deeper
: : Batch normalization <u>after</u> convolutions
: : Bottleneck architecture
: <br><b>DenseNet</b><br><br>
: : DenseNet uses concatenation instead of addition
: : Concat 할수록 채널의 수가 기하급수적으로 커진다 (파라미터 수가 같이 기하급수적으로 커짐)
: : 그래서 중간에 한 번씩 1x1 conv를 이용해 채널을 줄인다. (Transition Block)
: <br><b>퀴즈 5 틀린 문제</b><br><br>
: : Q. Skip Connection이 그래디언트 소실 문제를 어떻게 해결하나요?
: : A. 그래디언트를 직접 전달한다.(Skip Connection은 그래디언트가 직접적으로 뒤로 전달될 수 있도록 하여 그래디언트 소실 문제를 완화합니다.)

- (6강) Computer Vision Applications
: <br><b>키워드</b><br><br>
: - Semantic Segmentation, Object Detection
: <br><b><u>1. Semantic Segmentation</u></b><br><br>
: : 이미지의 모든 픽셀이 어떤 Label에 속하는지 구분하는 것
: : 자율주행 같은 문제에 가장 많이 활용된다. (RIDAR 와 같은 센서 없이 이미지로만 해결하는 문제들에 매우 중요하다)
: <br><b>Fully Convolutional Network</b><br><br>
: : Dense layer를 없애고 싶은 것.
: : Flatten 해서 벡터를 만드는 대신, convolutional filter를 만드는 것 (파라미터 수는 똑같다.)
: : Convolutionalization
: : 이를 하는 이유는 network가 heat map을 출력하게 하기 위해서
: : FCN는 어떤 input size(spatial dimension)에도 돌아가지만, output dimension이 일반적으로 줄어든다.
: : 이를 원래의 dimension으로 다시 늘리기 위한 방법이 필요함.
: <br><b>Deconvolution (conv transpose)</b><br><br>
: : convolution의 역연산
: : 근데 이미 합쳐진 정보를 어떻게 역으로 복원할까? (더해지기 이전의 정보를 복원할 수는 없다는 것)
: : 엄밀히 말하면 conv의 역은 아니지만, 네트워크 구조를 만들 때 parameter 숫자와 network 구조의 크기를 계산하는 데 있어서 편해진다.
: : (PDF 참조) 작은 사이즈의 아웃풋에 역으로 패딩을 많이 줘서 인풋 사이즈를 복원하는 과정인듯
: <br><b><u>2. Detection</u></b><br><br>
: : Per pixel이 아니라 Bounding box를 찾는 문제로 바꾼 것
: <br><b>R-CNN</b><br><br>
: : 가장 간단한 방법이 R-CNN
: <br><b>SPPNet</b><br><br>
: : Bounding box를 뽑고, 이미지 전체에 대해 Convolutional Feature Map을 만들어서 CNN을 한 번만 돌리려고 하는 방법
: <br><b>Fast R-CNN</b><br><br>
: : Bounding box를 2,000개 정도 뽑고, Conv feature map 한 번 얻고,
: : 각 region에 대해 fixed length feature를 뽑는 것 (Region of Interest Pooling)
: : 마지막에 NN을 통해 bounding-box에 대한 라벨을 찾게 된다.
: <br><b>Faster R-CNN</b><br><br>
: : Bounding box, 즉 candidate를 뽑는 것도 학습하자는 것 (Region Proposal Network)
: : Region Proposal Network이 하는 역할은, 해당 bounding box 안에 물체가 있는지 없는지를 판단해주는 것
: : 이 RPN 뒷단에 해당 region이 어떤 class에 속하는지를 맞추는 과정으로 이루어짐
: <br><b>YOLO</b><br><br>
: : extremely fast (baseline: 45fps / smaller version: 155fps)
: : 그냥 image 한 장에서 바로 찍어서(?) output 나오는 방식 (You Only Look Once)
: : In total, it becomes a tensor with SxSx(B*5+C) Size
: - SxS: Number of cells of the grid
: - B*5 : B bounding boxes with offsets(x,y,w,h) and confidence
: - C: Number of classes
: <br><b>6강 퀴즈</b><br><br>
: Q. Semantic Segmentation에 관한 다음 설명 중 틀린 것은?
: A. Semantic Segmentation은 이미지 분류 작업과 같다.
(이미지 분류는 전체 이미지에 대한 한 가지 레이블을 할당하는 반면, Semantic Segmentation은 각 픽셀에 레이블을 할당함.)
<br><br>

- (7강) Recurrent Neural Networks
: - Sequential Model, Recurrent Neural Networks, Long Short Term Memory, Gated Recurrent Unit
: <br><b>Sequential Model</b><br><br>
: : Naive sequence model
: : $p(x_t \vert x_{t-1},x_{t-2},...)$
: : 어려움 - 받아들여야할 입력의 차원을 알 수 없다.
: : 즉, 몇 개의 데이터가 들어오든지 상관없이 동작하는 모델이어야 한다는 것.
: : ex. Language model (이전 데이터들이 들어왔을 때 다음 번을 찾아보자)
<br><br>
: : <u>Autoregressive model</u> - Fix the past timespan $p(x_t \vert x_{t-1},...,x_{t-\tau})$
: : Markov model
: : 나의 현재는 바로 전 과거에만 dependent하다고 가정하는 것
: : ex) 내일의 수능 점수는 전날 공부한 것에만 dependent 하다?
: : Markovian Model은 많은 정보를 버릴 수밖에 없는데, 가장 큰 장점은 Joint Distribution을 표현하는 것이 굉장히 쉬워진다
: : Generative Model에서 굉장히 많이 활용된다.
<br><br>
: : <u>Latent autoregressive model</u>
: : $\hat{x} = p(x_t \vert h_t)$
: : $h_t = g(h_{t-1}, x_{t-1})$
<br><br>
: <br><b>Recurrent Neural Network</b><br><br>
: : 자기 자신으로 돌아오는 구조가 있는 것
: : 이전의 cell state에 dependent 한 것
: : 이를 시간순으로 길게 풀게 되면, 입력이 굉장히 많은 Fully connected layer로 표현될 수 있다.
: : 제일 큰 단점은 Short-term dependency이다. (Long-term dependency를 잡지 못한다.)
: : Vanishing / exploding gradient의 문제
: <br><br><b>LSTM (Long Short Term Memory)</b><br><br>
: : Previous cell state - 지금까지의 정보를 다 취합해서 가지고 있는 정보
: : 마치 컨베이어 벨트와 같다.
<br><br>
: **\<Gates\>**
: : <u>Forget gate</u> - Decide which information to throw away
: : $f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$
: : $\sigma$ 를 통과하므로 늘 0에서 1 사이의 값을 갖는다.
<br><br>
: :  <u>Input gate</u> - Decide which information to store in the cell state, Output gate
: : $i_t = \sigma(W_i \cdot [h_{t-1},x_t]+b_i)$
: : $\tilde{C} = tanh(W_C \cdot [h_{t-1}, x_t] + b_C)$
<br><br>
: : <u>Update cell (state)</u>
: : $i_t = \sigma(W_i \cdot [h_{t-1},x_t]+b_i)$
: : $C_t = f_t \cdot C_{t-1} + i_t  \cdot \tilde{C}_t$
: : 즉, Forget gate와 Input gate에서 나온 두 가지 값을 combine 해서 새로운 Cell state로 Update 하는 것이다.
<br><br>
: : <u>Output Gate</u>
: : Make output using the updated cell state
: : $o_t = \sigma(W_o[h_{t-1},x_t] + b_o)$
: : $h_t = o_t \cdot \mathbb{tanh}(C_t)$
: <br><b>Gated Recurrent Unit (GRU)</b><br><br>
: : Gate가 두 개만 있음.
: : Reset gate, Update gate
: : 같은 task에 대해 LSTM보다 GRU를 사용할 때 성능이 올라가는 경우를 꽤 본다.
: : (적은 파라미터로 좋은 성능을 내면 Generalization이 잘 되니까?)
: : 그치만 LSTM, GRU 모두 요즘은 잘 활용되지 않고 Transformer로 바뀌고 있는 추세
