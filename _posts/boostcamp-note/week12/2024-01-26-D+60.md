---
layout: single
title:  "Day 60 학습정리"
categories: boostcamp-note-week12
sidebar:
  nav: "docs"
---

24/01/26 (금) 학습 내용

<h1>Data Centric</h1>

<h2>(9강) Future of Data-Centric NLP</h2>
1. Multi-Modal Al<br><br>
: : 데이터의 양상(텍스트, 이미지, 오디오, 비디오 등)
: : From Uni-Modal to Multi-Modal
: : Real-world는 Uni-modal로 설명하기에는 복잡하기 때문
: : 대표적인 Multi-modal 데이터 구축 방식 -> Uni-Modal로 구축된 데이터에서 시작해서, 하나의 모달을 더 붙이는 방식으로 구축함
: : DialogCC -> Multi-Modal 대화 데이터셋
: : 이미지와 텍스트가 같이 있는 대화 데이터셋
: : MMDialog
: : 소셜 미디어에서 인간-인간 채팅 콘텐츠에서 파생된 multi-modal open domain 대화
: : VE (Visual Entailment) -> NLI와 비슷함
: : VQA v2.0
: : VQG (Generating Natural Questions About an Image)
: : TextVQA
: : OK-VQA
: : Visual Dialog
: : VCR (Visual Commonsense Reasoning) - 이미지로부터 상식을 추론
<br><br>
: : 데이터셋이 먼저 있으면 그에 대한 task가 나오고, 해당 task에 맞는 모델링이 나오는 흐름을 인지하면서 보자!
<br><br>
: : TextCaps
: : FFHQ-Text
: : SumMe (Creating Summaries from Video)
: : MSR-VTT
: : VidLN
<br><br>
: : Multi-Modal? Human?
: : Multi-Modal = AI를 더 사람처럼!
<br><br>

2. Neuro-Symbolic Al<br><br>
: : Neuro System과 Symbolic System의 특징 비교
: : 이러한 두 시스템의 장, 단점을 상호 결합 및 보완하는 것
: : 치열한 논쟁 (LLM Vs. Neuro-Symbolic)
: : Yoshua Bengio vs Gary Marcus
: : 다양한 Paper, Workshop, Book
: : Symbolic은 Reasoning을, Neural은 Learning을 담당하는 것
: : COMET - Common Sense 생성 연구
: : SODA - Common Sense를 이해한 Synthetic Data 생성 연구
<br><br>

3. Reinforcement Learning with Human Feedback<br><br>
: : RL의 기본 아이디어는 agent가 자신이 행동하는 environment와의 상호작용을 통해 학습한다는 것
: : 자연어처리와 RL을 결합하려는 시도가 많음
: : agent = LM
: : environment - LM의 input, 즉 prompt
: : action = token 및 sequence 생성
: : reward = RM의 output
<br><br>
: : 대부분의 언어 모델이 사용하는 loss function (e.g., cross entropy)는 이러한 속성을 포착하는 데에 한계가 존재하므로,
: : 이를 해결하기 위해 생성된 텍스트에 대한 인간의 피드백을 척도로 사용하고, 한 걸음 더 나아가 모델을 최적화하기 위해 그 피드백을 loss로 사용하는 것이 Reinforcement Learning from Human Feedback (RLHF)의 아이디어임
<br><br>
: : Pre-train Language Model (LM)
: : Gathering data and training a reward model
: : Fine-tune language model with reinforcement learning
<br><br>

4. GPT-4<br><br>
: <b>LLM + Multimodal + RLHF</b><br><br>
: : Creativity
: : Visual Input
: : Longer Context
<br><br>
: : 논문 요약 가능 (이미지 그 자체를 OCR해서 요약)
: : 수능 국어 3등급정도 나왔다고도 함
: : 만화도 이해함
: : Chart 추론
: : 다양한 업무 향상에 도움을 받을 수 있다
<br><br>
: : 그러나 Technical Report에서 중요한 노하우들은 숨겼다고 함
: : ChatGPT에서 사용자들이 넣었던 프롬프트와 그에 대한 하나의 응답을 수집해, 이 프롬프트와 응답을 human labeler에게 '사용자가 원했을 응답을 했는지 여부'를 라벨링하도록 하였다. 
<br><br>
: : 한계점 - Hallucination Problem (가짜를 그럴듯하게 말하는 것)
: <br><b>잘 활용할 줄 알아야</b><br><br>
: : 산업혁명이 노동의 자동화였다면, AI혁명은 지식의 자동화
: : 너무 거부하거나 맹신하지 말고, 업무에 인턴 / 비서처럼 잘 활용할 필요가 있다.