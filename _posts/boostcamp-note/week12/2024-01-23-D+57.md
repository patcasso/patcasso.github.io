---
layout: single
title:  "Day 57 학습정리"
categories: boostcamp-note-week12
sidebar:
  nav: "docs"
---

24/01/23 (화) 학습 내용

<h1>Data Centric</h1>

<h2>(2강) Data-Centric AI - In the Wild</h2>

1. Data-Centric AI<br><br>
: <br><b>Data-Centric AI란 대체 무엇?</b><br><br>
: : MLOps - AI Lifecycle for IT Production
: : LLMOps - LLM Ops from Naver Cloud ~ LM(AI) as a Service
: : LLM을 효율적으로 서비스하기 위한 운영체제가 필요하게 되었다.
: <br><b>AI Service 개발 사이클 고도화</b><br><br>
: : Model Centric vs Data Centric
: <br><b>Data 중심의 AI 프로젝트 개선 방향</b><br><br>
: : 제품 출시 전에는 model centric이 50% 정도 차지하지만,
: : 출시 후에는 data centric 이 80% 정도를 차지한다.
: <br><b>Definition of Data-Centric AI</b><br><br>
: : 모델 변경 없이 어떻게 모델의 성능을 향상 시킬 수 있을까?
: <br><b>Data-Centric AI의 탄생</b><br><br>
: : Andrew Ng에 의해 2022년에 만들어진 용어
<br><br>

- Data-Centric AI in Real-World<br><br>
: <br><b>Data-Flywheel</b><br><br>
: : 기업의 입장에서는, 어떤 서비스를 하다 보면 지속적으로 데이터가 쌓이게 된다.
: : 이런 데이터를 모델의 학습 데이터로 가공하고, 추가 학습을 진행하면 인식 성능이 높아지게 된다.
: : 이것이 Data-Flywheel (데이터를 기반으로 모델의 성능까지 높아지는 선순환 체계)
: <br><b>Data-Flywheel X Upstage AI Pack</b><br><br>
: : Upstage에서 만든, 데이터 Flywheel을 No code로 할 수 있도록 구현한 제품
: <br><b>DMOps</b><br><br>
: : Data Development
: <br><b>Data Labeling Tool</b><br><br>
: : 사람들이 효율적으로 라벨링 할 수 있도록 하는 툴
: <br><b>Data Team Process</b><br><br>
: : 서비스 기획자, AI 모델 개발자, 외주 업체 등과 소통하며 진행
<br><br>

- Data-Centric AI in Academia<br><br>
: : 학계에서는 왜 Data-Centric AI를 하기 힘들까?
: : 학계에서 데이터를 다루기 힘든 이유들
: <br><b>1) 좋은 데이터를 많이 모으기 힘들고, 데이터는 아직 미지의 영역이다</b><br><br>
: <br><b>2) 라벨링 작업에 대한 명확한 정답이 없고 비용이 크다</b><br><br>
: : 일관성 있게 라벨링된 데이터
: : 중요한 케이스가 포함된 데이터
: : 예상치 못한 케이스까지 포함한 데이터
: : 적절한 크기의 데이터
: : => 특이 경우를 발견하고 해당 샘플들을 모으며, 이를 포함한 라벨링 가이드를 만들어야 한다!
: <br><b>3) High Quality Data가 필요하다 (데이터의 양 < 데이터의 질)</b><br><br>
: : 적은 데이터여도 레이블이 클린하고 일관성이 있으면 훨씬 좋은 모델을 만들 수 있다.
: : 시간이 많이 들기 때문에, 이것이 학계에서 연구하기 힘든 이유이다.
: <br><b>4) 데이터의 균형이 맞아야 한다</b><br><br>
: : 적은 양이라도 데이터가 골고루 있어야 함
: <br><b>학계는 정해진 테스트셋 내에서 경쟁하는 방식이다</b><br><br>
: : 데이터는 정해진 테스트 방식이 있다. 그러므로 모델링에 치중하게 된다.
: : 그러나 real world에서는 데이터셋이 존재하지 않는 경우가 대부분이므로, 직접 처음부터 구축해야 한다.
: <br><b>DataPerf</b><br><br>
: : ML 데이터 품질 향상을 위해 Data-Centric 파이프라인의 주요 단계를 벤치마크
: : 데이터셋을 쉽고 반복 가능하게 유지 관리 및 평가


<h2>(3강) Data-Centric AI의 핵심 - Data Management</h2>

1. DMOps<br><br>
: : Data Management Operation and Recipes
: <br><b>인공지능 개발을 위한 데이터</b><br><br>
: : 인공지능의 역사가 길지만, Task와 Data는 그대로이다
: : text, corpus, data의 차이
: <br><b>데이터 관련 용어 정리</b><br><br>
: : 언어학의 연구 분야
: : 음성학, 음운론, 형태론, 통사론 등.. 
: <br><b>DMOps</b><br><br>
: : 데이터 관리에 대한 baseline을 정해준다
: : 체계적으로 데이터를 관리하는 체계적인 프로세스
: : NLP 데이터 제작에 대한 연구가 부족한 상황임
: : 데이터를 생산하는데 일관성 있고 신뢰할 수 있는 고품질의 데이터를 생산할 수 있는 것
: <br><b>1) Establish the Project Goal</b><br><br>
: <br><b>2) 원시 데이터 조사 및 수집</b><br><br>
: : 고객사에서 데이터 제공
: : 자체적 크라우드 소싱(인하우스 작업자)
: : 크롤링
: : 사내 내부 이벤트
: : 공공 데이터 활용
: : 법무적 검토를 거쳐야 함
: : 제한된 액세스 권한을 제공해야 함
: <br><b>3) Data Pre-processing</b><br><br>
: : 데이터에 내재된 특성을 바탕으로 품질 향상
: : 중복 확인(Deduplication), 특수문자 50% 이상 제거 등
: : 비윤리적, 사생활 침해, 노이즈 데이터 필터링
: : 크롤링 개인 식별 정보 - 개인 식별 정보 탐지
: : 정제 기준이 명확해야 함
: <br><b>4) Design a Data Scheme</b><br><br>
: : Self-supervised Learning을 통해 Pseudo-labeling
: : 모델이 초안으로 Inference를 해주고, 사람이 그걸 고치는 게 훨씬 빠르다.
: <br><b>5) Prepare a Guideline</b><br><br>
: : 처음 접하는 작업자의 입장에서 모든 edge case를 다 하면 어려울 수 있으므로,
: : 명확한 목적과 작업 방식을 담아 문서의 난이도를 잘 조율해야 함
: <br><b>6) Recruit Annotators</b><br><br>
: : 좋은 데이터셋을 만들기 위해 적합한 작업자 선정
: : 작업자에게 정당한 보상을 주는 윤리적인 부분도 고려해야 함
: : 내부조직, 아웃소싱, 크라우드소싱의 분류가 있다.
: <br><b>7) Instruct Annotators</b><br><br>
: <br><b>8) Data Annotation</b><br><br>
: : 실제 데이터 구축하는 단계
: : 잘 설계된 Data Annotation Tool을 통해 데이터를 라벨링해야 함
: : Quality Control, Efficiency, Scalability
: : 파일럿 - 설계 시 발견하지 못한 이슈 발굴 및 해결, 가이드라인 보완 및 개정, 작업자 선정
: : 본 구축 - 작업 일정 관리, 작업자 관리, 중간 검수를 통한 데이터 품질 관리
: <br><b>9) Data Inspection</b><br><br>
: <br><b>10) Data Verification</b><br><br>
: : 데이터 검수 및 분석
: : 전문가 평가 및 분석 / 자동 평가 및 분석
: <br><b>11) Data Evaluation via Model Verification</b><br><br>
: : 실제 모델링을 통해 데이터 품질을 평가하는 단계
: <br><b>12) Data Deliverables</b><br><br>
: : 최종 데이터 산출물을 전달할 때는 프로토콜에 맞는 버져닝이 중요
: : 더 나아가 EDA 과정을 거친 후, 데이터 분석서 및 품질 평가서를 함께 전달하면 가장 좋음
<br><br>

2. Data Annotation Tool<br><br>
: <br><b>HAMT (Human Aided Machine Translation)</b><br><br>
: : Pre-editing : 번역 모델이 번역하기 전 사람이 원문의 문법 및 맞춤법, 문체 및 재구성, 철자 수정, 의미 보강 등 원본 문장을 수정
: : Post-editing: 기계번역 결과에 대한 번역가의 오류 발견 및 수정, 여러 번역 결과 중 좋은 번역 결과를 선택함
: : 장점 - 사람이 직접 번역한 결과보다 훨씬 빠른 속도, 잘 학습된 모델은 우수한 성능을 기대할 수 있음
: <br><b>CAT(Computer Aided Translation) 툴</b><br><br>
: : 기계 번역에서의 대표적 Annotation Tool
: <br><b>Annotation Tool 예시</b><br><br>
: : Doccano, Brat(Browser-Based Rapid Annotation Tool), TagEditor, Tagtog, LightTag, Label-Studio, Upstage Data Labeling Space
<br><br>

3. Data Software Tool<br><br>
: : CleanLab - 노이즈 데이터 자동 디텍팅
: : Snorkel
: : Refinery
: : Great Expectations
: : ydata-profiling
<br><br>

4. 크라우드소싱<br><br>
: <br><b>대표적 업체들</b><br><br>
: : 셀렉트스타
: : 딥네츄럴
: : 텍스트넷
: : 에이모
: : Appen
: : Scale.ai - MLOps와 워크플로우 단계까지 제공