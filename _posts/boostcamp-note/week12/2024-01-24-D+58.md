---
layout: single
title:  "Day 58 학습정리"
categories: boostcamp-note-week12
sidebar:
  nav: "docs"
---

24/01/24 (수) 학습 내용

<h1>Data Centric</h1>

<h2>(4강) </h2>

1. 국내 NLP 데이터 구축 프로젝트 소개<br><br>
: : 데이터 구축 주체에 따른 분류 (국가, 기업, 개인)
: <br><b>21세기 세종 계획 (1997~2007, 국립국어원)</b><br><br>
: : 총 2억 어절의 자료 구축, 공개
: <br><b>KAIST Corpus (1997~2005, KAIST)</b><br><br>
: : 한국어와 Multilingual Corpus Dataset
: <br><b>엑소브레인 (2013~2023, ETRI)</b><br><br>
: : 언어를 이해하고 지식을 학습하여, 전문가 수준의 지식을 서비스하는 언어지능 SW 를 중점적으로 개발하기 위함
: : 1단계 - 일반분야 대상 분석형 엑소브레인 SW 기반기술 개발
: : 2단계 - 전문분야 대상 엑소브레인 SW 응용기술을 개발
: : 3단계 - 설명가능한 심층질의응답
: : ETRI의 OPEN AI API에서 데이터셋 배포 (신청하면 다운로드 가능)
: <br><b>모두의 말뭉치 (2016~, 국립국어원)</b><br><br>
: : 굉장히 많은 종류의 말뭉치 데이터가 오픈되어 있음
: <br><b>우리말샘 (2016~, 국립국어원)</b><br><br>
: : 누구나 자유롭게 제작, 이용하는 국어사전
: <br><b>AI허브 (2016~, NIA)</b><br><br>
: : 프로젝트 목표 및 결과물
: : 데이터별로 데이터 설명서, 구축활용 가이드 제공
: : JSON, 엑셀 등 다양한 형식의 데이터 제공
: : 실제 산업계 수요 조사를 반영하여 다양한 TASK를 수행할 수 있는 자원 구축
: : 데이터 예시 - 온라인 구어체 말뭉치 데이터
: <br><b>뉴스 빅데이터 (2020, 한국언론진흥재단)</b><br><br>
: <br><b>데이터 댐</b><br><br>
: : 과기정통부 주도 - 디지털 뉴딜
: <br><b>데이터 바우처사업</b><br><br>
: : 과기정통부 주도 - 데이터 지원 사업 - 데이터 생태계 확대
: : 크라우드소싱 업체들과 연결해주는 것
: <br><b>KorQuAD 1.0 & 2.0 (2019, LG CNS)</b><br><br>
: : 질문답변 20,000+ 쌍을 포함하여 총 100,000+ 쌍으로 구성된 한국어 기계 독해 데이터셋
: <br><b>KLUE dataset (2021~)</b><br><br>
: : 한국어 이해 능력 평가를 위한 벤치마크
: : KLUE TC - 뉴스 헤드라인에서 어떤 도메인인지 분류하는 것 (이번 대회)
: <br><b>KorNLI (2020, Kakao Brain)</b><br><br>
: <br><b>KorSTS (2020, Kakao Brain)</b><br><br>
: <br><b>KOBEST (2022, SK Telecom)</b><br><br>
: : BoolQ - 질문이 참인지 거짓인지를 판단하는 Task
: : COPA - 원인/결과인 alternative를 선택하는 task
: : WiC - 두 context에서 target word가 같은 의미 가지는지 판별하는 task
: : HellaSwag - 주어진 context 뒤에 나타날 문장을 선택하는 task
: : SentiNeg - 부정문의 polarity를 예측하는 task
<br><br>
: <br><b>개인 주도</b><br><br>
: <br><b>NSMC (2016)</b><br><br>
: : Naver Sentiment Movie Corpus
: : Naver 영화에서 크롤링한 데이터 활용
: : 박은정님이 대학원 시절에 혼자 만들어서 Open한 데이터
: <br><b>Korean Comment Corpus</b><br><br>
: : 한국어 댓글 데이터셋
: <br><b>Korean Hate Speech - BEEP (2020)</b><br><br>
: : 욕설 데이터
<br><br>
: <br><b>학계 주도</b><br><br>
: <br><b>KorLex</b><br><br>
: : 워드넷은 영어의 의미 어휘목록임
: : 시소러스 형식 : 단어에 대한 값을 키워드의 뭉치로 나타내고, 키워드의 뭉치로 나타내고, 단어에 대한 유의어의 그룹으로 묶는 방식
: <br><b>Korean WordNet</b><br><br>
: : 카이스트 최기선 교수님 연구실
: : 한국어 버젼의 워드넷
: <br><b>UWordMap</b><br><br>
: : 울산대학교 옥철영 교수님 - UWordMap (Lexical Semantic Network)
: : Lexical Semantics
: <br><b>USenseVector, UConceptVector, UTagger</b><br><br>
: <br><b>한통이: 자연언어처리 기반 다국어 어휘대역 서비스</b><br><br>
: : 다문화 가족 삶의 질 향상을 위해 외국인의 우리말 이해도 향상 도모
: <br><b>Korean CommonGen</b><br><br>
<br><br>


2. 해외 NLP Benchmark 데이터 소개<br><br>
: : NLP는 NLU, NLG로 나뉜다 (NLU는 인코더, NLG는 디코더 혹은 인코더/디코더 모델들이 더 잘 한다)
: : 언어학에서는 NLP를 전산언어학 이라고 부른다
: <br><b>자연어 추론 (NLI)</b><br><br>
: : 주어진 문장들의 관계(contradiction, neutral, entailment) 를 구분
: <br><b>개체명 인식 (NER)</b><br><br>
: : CoNLL 2003 - 영어와 독일어로 되어있는 dataset
: <br><b>관계 추출 (RE)</b><br><br>
: : TACRED 데이터셋
: <br><b>기계 번역</b><br><br>
: : WMT 데이터셋이 가장 유명함
: <br><b>대화 시스템</b><br><br>
: : Wizard-of-Oz 데이터셋
: : DSTC - Dialog System Technology Challenges
: <br><b>Text Summarization</b><br><br>
: : CNN/Daily Mail
: : 추상 요약 말뭉치
: <br><b>기계 독해</b><br><br>
: : SQuAD, SQuAD 2.0
: : 위키피디아 데이터를 기초로 질문-답변 데이터셋
: <br><b>GLUE Benchmark</b><br><br>
: : 9개의 task를 수행하도록 하는 benchmark
: <br><b>SuperGLUE Benchmark</b><br><br>
: : GLUE 보다 더 어려운 Task
: <br><b>Generation Benchmark</b><br><br>
: : Gem Benchmark
: <br><b>MultiTask Benchmark</b><br><br>
: <br><b>Big Benchmark</b><br><br>
: : 200개 이상의 task를 수행하도록 하는 benchmark
<br><br>

3. Multilingual Benchmark 데이터 소개<br><br>
: : Meta AI에서 multilingual 데이터를 많이 제공하고 있다.
: : LASER, LASER2
: : M2M
: : Flores
: : NLLB (No Language Left Behind) - Low resource language를 포함하고 있다
: : Low resource language 번역 성능을 통해 언어간 격차 해소


<h2>(5강) NLP 분야의 특이한 Task 및 Data 소개</h2>

1. Hate Speech & Offensive Language 관련 특이한 Task 및 Data<br><br>
: : Hate Speech는 인종, 성적 지향, 종교, 출신 국가, 성별 등에 따라 사람들을 비하하거나 공격하는 언어
: : Binary 분류하거나, 계층별로 multi-classification task로도 볼 수 있다.
: : 대표 데이터셋 - HateXplain
: : rationale - post의 레이블링을 결정하는 post의 일부분
: <br><b>Counter Speech Generation</b><br><br>
: : 가짜 뉴스 및 허위 정보 등에 대하여 모델이 적절하게 대응할 수 있도록 하는 것
: : 대표 데이터셋 - ProsocialDialog
: <br><b>Sarcasm Detection</b><br><br>
: : Hate speech보다 조금 더 challenging한 task이다
: : 매우 중요한 태스크로 인식되고 있다.
: : 소셜 미디어, 비즈니스 분야 등 활용 가능성
: : 대표 데이터셋 - iSarcasm
<br><br>

2. Deception Detection 관련 특이한 Task 및 Data<br><br>
: <br><b>Fake News Detection</b><br><br>
: : Fake News Detection은 기존의 분류 기술을 활용하여 구현됨
: : 대표적 데이터셋 - LIAR
: <br><b>Fact Checking</b><br><br>
: : 대표적 데이터셋 - FEVER
: : Claim이 주어지고, 사실인지 아닌지 레이블링, 그리고 evidence도 제공
: : GPT등의 Hallucination을 이런 분야로 검증할 수 있다.
<br><br>

3. Machine Translation 관련 특이한 Task 및 Data<br><br>
: : Machine Translation에 정말 많은 하위 task들이 있다.
: <br><b>MWT Shared Task</b><br><br>
: : 특이한 Task들이 있으니 가서 확인해보기
: <br><b>Quality Estimation</b><br><br>
: : 기계 번역의 품질을 예측하는 것을 말함
: : 원래는 번역이 완료된 문장과 정답 label로 BLEU 점수를 내야 하는데, 정답 label 없이 Evaluation 하려는 것
: : 원문-번역문 Pair의 번역 품질을 예측하는 기술
: : 내가 모르는 언어에 대해 기계 번역을 한다 해도, 잘 된 번역인지 아닌지가 알 수 없다. 이럴 때 필요한 것이 QE 모델!
: : Sentence-level QE, Word-level QE, MQM word-level QE
: : 대표적인 데이터셋 - QUAK (한국어)
: <br><b>Automatic Post Editing</b><br><br>
: : 기계번역 결과를 자동으로 수정하는 기술
: : 이전 번역 결과를 고려하여 수정을 수행하는 기술
: : 이 경우는 Source 뿐만 아니라, Machine Translation Sentence, Post Editing Result Sentence까지 세 가지의 데이터가 필요하게 된다 (SEP 토큰을 이용하든, 여러 가지 형태로 인풋)
: : 대표적 데이터셋 - SubEdits
: <br><b>Chat Translation</b><br><br>
: : 채팅 번역
: : 게임 회사 등은 문어체가 아닌 구어체의 채팅 번역이 필요하다
: : 코멧도 이런 식으로 '방송 Translation' 특화된 번역이 필요하지 않을까? (Fine-tuning 개념)
<br><br>

4. Dialogue 관련 특이한 Task 및 Data<br><br>
: <br><b>Persona-grounded Dialogue</b><br><br>
: : 사용자의 성격, 상황, 인적 정보 등을 고려해서 대화하는 것
: : 대표 데이터셋 - PersonaChat
: : Personalizing Dialogue Agents - I have a dog, do you have pets too? (Meta AI)
: : 대표 데이터셋 - BSBT
: : BotsTalk
: <br><b>Persuasive Dialogue</b><br><br>
: : 모델이 상대방을 설득하고 자신의 주장을 전달하기 위해 응답 발화를 생성하는 것을 말함
: : 대표 데이터셋 - Persuasion for Good
: <br><b>Dialogue Summarization</b><br><br>
: : 문서가 아닌, 대화를 요약해주는 Task
: : 대표 데이터셋 - DialogSum, SAMSum
: <br><b>Knowledge-grounded Dialogue</b><br><br>
: : 딥러닝의 한계 중 하나로 지적받는 것이, 상식 정보가 없다는 것
: : ex) 한국에서 미국까지 걸어서 못 간다는 것을 모르는 경우가 있다.
: : 데이터셋 - Wizard of Wikipedia, Wizard of Internet
: <br><b>Dialogue for characters</b><br><br>
: : 대표적인 데이터셋 - Harry Potter Dialogue(HPD)
: <br><b>Empathetic Dialogue</b><br><br>
: : 상대방의 감정을 고려하고 이를 공감하는 대답을 생성하는 것임
: : 스캐터랩에서 개발한 '이루다' - 사용자의 호응이 더 올라가게 됨
: : 얼마나 많은 Turn을 왔다갔다 하는지가 중요한 성공 지표이므로, 이러한 부분을 연구해야 한다.
: : 대표 데이터셋 - EmpatheticDialogues(ED), DailyDialog
<br><br>

5. 기타 특이한 Task 및 Data<br><br>
: <br><b>ImageNet-X</b><br><br>
: : ImageNet을 확장한 데이터셋
: : 실제 세계에서 발생하는 다양한 왜곡 요인을 추가하여 구축됨
: <br><b>Question Generation</b><br><br>
: : 주어진 지문과 목표 답변에 따라 유효하고 유창한 질문을 생성하는 것을 말함
: : AI for Education 분야에서 굉장히 중요함
: : ex) TOEIC 문제를 만드는 AI
: : 챗봇이 대화를 이끌 수 있도록 하는 데에 활용됨
: : 데이터셋 in 논문 - Question Generation for Question Answering
: <br><b>Document-level Relation Extraction</b><br><br>
: : 문서 전체에서 개체에 대한 속성과 관계를 예측하는 것을 말함
: : 대표 데이터셋 - DocRED
<br><br>

6. 한국어 관련 특이한 Task 및 Data<br><br>
: <br><b>고전어 데이터셋 (Ancient Korean Neural Machine Translation)</b><br><br>
: : 전문가 양성에 굉장히 오랜 시간이 든다.
: : 기계번역으로 하면 효율성이 훨씬 좋아질 것이다.
: <br><b>케어콜 데이터셋</b><br><br>
: : 독거노인 도와주는 케어콜 관련 데이터셋
: <br><b>혐오 발언 탐지 데이터셋</b><br><br>
: : BEEP, APEACH, Korean UnSmile Dataset, KOLD
: <br><b>쓰기 평가 데이터셋</b><br><br>
: : 쓰기 평가 자동 점수 데이터셋
: <br><b>문법 교정 데이터셋</b><br><br>
: : K-NCT
<br><br>

<h2>(6강) Data-Centric을 통해 재해석하는 History of NLP</h2>

1. 규칙 기반 NLP<br><br>
: : 전문가의 시대
: : 데이터 관점에서의 사람에 대한 정의 - 전문가, 모두(군중, 여러분)
: : Rule에 맞게 처리하는 시스템
: : Rule 생성을 위해서는 Task에 대한 전문 지식 필요
: : 데이터 구축에 있어서도 전문가가 필요함
: : ex) 규칙기반 기계번역 - 전문가에 의해 이루어졌고, 언어학적 지식이 중요했다.
<br><br>

2. 통계 기반 NLP(SMT, Statistical Machine Translation)<br><br>
: : 대량의 텍스트 데이터로 통계를 내어 단어를 표현
: : 모두(군중)이 무의식적으로 생산한 대량의 데이터(=빅데이터)를 활용
: : ex) 네이버 지식 iN, 카페 등
: : 웹 상의 데이터가 점점 많이 쌓이게 되었기 때문
: : "Sparsity Problem"으로 인한 한계 도달
: : (충분한 양의 데이터를 사용하지 못하여 언어를 정확하게 modeling 하지 못하는 문제점)
<br><br>
: : 규칙 기반 NLP에 비해 전문가의 중요성 감소
: : 합리주의자(규칙기반, ex. 노엄 촘스키) VS 경험주의자(현재의 딥러닝, ex. 제프리 힌튼)
: : 여러 Component 조합으로 시스템 구성 (Translation model, Language model, Re-ordering model)
<br><br>

3. Machine Learning 및 Deep Learning 기반 NLP<br><br>
: : "전문가" + "모두(군중, 여러분)" 공존의 시대
: : 규칙기반 vs ML 및 DL 기반 - 장단점 비교 in 강의자료
: : Machine Learning과 Deep Learning의 차이는, Machine Learning은 Feature를 직접 추출해야 했다는 것인데 Deep Learning은 Feature 마저도 자동으로 추출한다는 것! (End-to-End)
<br><br>
: : Neural Machine Training -> 과정이 End-to-End로 아주 단순화되었기 때문에, 딥러닝이 굉장히 각광을 받게 되었다.
: : 지도학습과 비지도학습
: : 세부적인 fine-tuning은 여전히 지도학습이 중요하다
: : Unsupervised Learning Approach 예시 - 모두(우리, 군중)
: : RoBERTa -> Dynamic masking
: : Language Model = 지식표현 체계
: : 인간의 언어를 컴퓨터가 이해할 수 있도록 만든, 숫자로 변환된 지식표현 체계
<br><br>

4. Pre-train & Fine-tuning 기반 NLP<br><br>
: : 대중이 만든 데이터(Pre-train) + 전문가가 만든 데이터(Fine-tune)
: : 대량의 말뭉치로 언어 능력을 pre-training 이후 task-specific fine-tuning
: : 벤치마크의 등장 ~ Task-specific benchmark dataset 대량 등장
: : 영향력 - Transformer 등장 이후로 NLP 연구의 메인 트렌드가 됨
: : 다양한 Transformer variants 연구도 활발해짐
<br><br>

5. Neural Symbolic NLP<br><br>
: : 전문가의 시대
: : 전문가의 데이터를 전면 활용 (상식정보, 추론 능력 등 딥러닝 모델의 한계를 보완하기 위해)
: : 9강에서 다시 자세히 설명
<br><br>

6. Large Language Models<br><br>
: : 모두의 시대 - 무의식적 데이터 생성
: : Fine-tuning은 weight를 업데이트 한다는 것이므로, 모델이 커질수록 이것이 힘들게 된다.
: : 모델이 점점 커지지만, weight 업데이트를 할 수는 없으니까 In-context learning 하려고 등장한 것이 Large Language Model
: : 더 많은 데이터를 부어 넣자!
: : 국내 및 해외 다양한 기업이 자신만의 LLM 개발
: : Foundation Models
: : 정말 많은 데이터로 학습한 Foundation Model을, 'Adaptation(In context learning)'을 통해 (or LORA, Prompt Engineering를 통해) 세부 task를 해결하려 함
: : In-Context Few-Shot Learning & Prompt Learning (예시를 주는 것, 그 문맥을 통해 학습을 하기 때문에 이렇게 부르는 것)
: : 이런 여러 태스크가 가능한 이유는 큰 데이터로 학습을 하다보니 다양한 태스크에 대한 능력이 생겼기 때문
: : Meta의 LLaMA - parameter 크기가 65B 밖에 안 되는데도 비슷한 성능을 거두었다 + 오픈된 데이터만 이용해서 트레이닝했다
<br><br>

7. Human FeedBack Data 기반 NLP<br><br>
: : ChatGPT의 성능을 끌어올린 가장 핵심적인 요인
: : 무의식적인 데이터 생성이 아닌, 모델에게 피드백을 주기 위한 데이터를 으식적으로 생성 (의식적 데이터 생성 = 피드백)
: : ex1. 사람이 질문에 직접 대답하기
: : ex2. 사람이 답변의 순위를 평가하기
: : 사람의 피드백이 담긴 '보상 함수'를 사용해서 학습한다.
: : 인간의 리워드로 'fine-tuning' 된 것이므로, pre-trained => fine-tuning과 똑같다고 보면 된다.
: <br><b>검색으 새로운 패러다임</b><br><br>
: : 기존에는 키워드 검색을 통한 정보 제공
: : ChatGPT의 경우는 우리가 을이 아니고, 주도권이 사용자에게 있다. 검색의 패러다임이 완전히 변했다고 볼 수 있다.
: : 다양한 능력을 가진 ChatGPT
: : 그 중심엔 Prompt Engineering
: : 다양한 능력들을 Digging 하는 것
: : Prompt Engineering 이라는 직업도 등장한 것!
<br><br>




