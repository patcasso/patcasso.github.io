---
layout: single
title:  "Day 29 학습정리"
categories: boostcamp-note-week6
sidebar:
  nav: "docs"
---

23/12/14 (목) 학습 내용

<h1>NLP 기초 프로젝트</h1>

<h2>(6강) Huggingface</h2>
- 강의 키워드<br><br>
: - Huggingface
: - Pre-trained model 
: - Model load

- 소개<br><br>
: : 1) Transfer Learning
: : 2) Why HuggingFace
: : 3) What is HuggingFace?
: : 4) How do we use it?
<br><br>

- Transfer Learning <br><br>
: : 전이 학습
: : 바닥부터 시작하지 말고, 한 분야에 전문적인 모델을 다른 분야로 어떻게 부드럽게 transfer 할지 고민하는 방법론
: <br><b>Pretraining & Fine-tuning</b><br><br>
: : 특정 분야의 label된 데이터는 구하기 힘들고 비싸고, 양도 적다.
: : 이전에는 이런 Small-Scale Tagged Data를 항상 바닥부터 시작해서 학습해나가고 있었다.
: : Small-scale로 매번 이렇게 바닥부터 하지 말고, Large-Scale Raw Data를 통해 먼저 학습한 모델의 지능을 전이시키는 방법론
: : 이렇게 Fine-tuning한 모델이 SOTA(State Of The Art)의 성능을 보이는 것을 확인
: : 이것이 2018년 정도인데, ELMO, BERT 등이 발표되었다.
<br><br>
: <br><b>BERT</b><br><br>
: : Pretraining & Fine-tuning을 잘 입증한 모델
: : 대규모 말뭉치들을 활용해 오랜 기간 pretraining을 수행
: : Masked language model로 훈련시킴
<br><br>
: : 각각의 언어에 맞게 잘 훈련된 후 배포된 transformer들을 우리가 이용해서 fine-tuning 해야 한다는 것!
: : 내가 가진 Small-scale의 현업 데이터를 training 시키면 되는 것이다.
<br><br>

- Why HuggingFace?<br><br>
: : 모델을 훈련시키는 사람과 사용자 간의 공통된 Interface의 존재 필요성
: : cf) 기찻길의 규격에 맞는 여러 호환 가능한 기차
<br><br>
: : 이미 좋은 성능을 내도록 만들어진 기존의 architecture들을 다른 사람들이 활용할 수 있도록 도와주는 것
<br><br>
: : ML 기반 자연어 처리 모듈에 필요한 3가지 자원
: : 1) Model(현재 대부분은 Transformer) Parameter
: : 2) 어휘 사전 (Token, embedding value)
: : 3) Tokenization 방법 (코드)
<br><br>
: : 이전에는 논문을 저자로부터 어렵게 구해서, 내 컴퓨터에서 직접 구현했어야 하는데
: : 이제는 좋은 논문이면 HuggingFace에 동시에 발표하는 것이 일반화 되어있다.
<br><br>

- What is Huggingface?<br><br>
: : 다양한 분야에 대한 Pretrained 모델들이 많으므로, 어떤 프로젝트를 시작하기 전에 먼저 여기서 검색해보면 많은 수고를 줄일 수 있다.

- How do we use it?
: : Google의 BERT를 HuggingFace에서 PyTorch용으로 transformers 모듈로 만들어놓았다.
: : 자주 반복되는 주요 Utility (예 - 문장생성) 등이 제공됨 (Beam Search 등)

<h2>(7강) N21</h2>

- 강의 키워드<br><br>
: - N21
: - 분류 문제(Classification)

- Neural Network based Classification<br><br>
: <br><b>접근 방법</b><br><br>
: : Supervised Learning + Classification
: : 이 테크닉은 거의 비슷한 형태를 취한다.
<br><br>
: <br><b>감성 분류기 구현 예</b><br><br>
: : 전형적인 N21 문제 중 하나
: : 기획 단계에서 종류(Classification)을 몇 가지로 정의할지부터 시작해야 한다.
: : ex) Positive, Negative, Neutral, Objective
: : 일단 데이터의 라벨을 사람이 직접 분류해야 한다. 굉장히 비싼 데이터가 된다.
<br><br>
: <br><b>신경망 디자인</b><br><br>
: : N개 Class 정의 후
: : Big & Deep Network 구성
<br><br>
: <br><b>신경망 분류 기법</b><br><br>
: : 정답을 어떻게 표현할 수 있을까?
: : 좋은 데이터를 넘겨줘야 좋은 답이 나올 것이다.
: : 문장과, 이에 해당하는 Label
