---
layout: single
title:  "Day 31 학습정리"
categories: boostcamp-note-week7
sidebar:
  nav: "docs"
---

23/12/18 (월) 학습 내용

<h1>NLP 기초 프로젝트</h1>

<h2>(7-3강) N21 (3)</h2>
- N21 Problem<br><br>
: <br><b>N21 문제는 무엇일까?</b><br><br>
: : N개의 input으로 1개의 output을 구하는 문제.
: : Encoder + Fully Connected Layer 형태의 모델을 사용
<br><br>
: <br><b>Encoder + Linear</b><br><br>
: : Encoder 기반 분류기의 구조
<br><br>
: : <요약>
: : Input / Output Modeling
: : 1) 입력을 적절한 단위로 Tokenization
: : 2) Tokens에 대해 Encoder가 Sentence Encoding 수행
: : 3) Encoder의 최종 Output Vector를 Classification을 위해 class 개수만큼의 차원으로 Projection
<br><br>
: <br><b>Example : Spam Classifier</b><br><br>
: : - Input : SMS(문자메시지)
: : Encoder
: : Fully Connected Layer
: : - Output : 스팸 여부 (spam / ham)
<br><br>
Example : News Classification (KLUE YNAT)
: : - Input : 뉴스 기사 제목
: : - Output : 기사의 주제 클래스
<br><br>

- Input / Output<br><br>
: <br><b>Tokenization</b><br><br>
: : 앞 뒤에 [CLS], 뒤에 [SEP] 토큰이 추가된다.
: : attention_mask - [PAD] 정보에 해당하는 것들은 attention_mask에서 0 값으로 들어간다.
<br><br>
: : Output
: : Logits 값이 보통 출력되고, 이를 softmax를 통해 확률 분포로 바꾼다.

- Loss<br><br>
: : N21에서 Output이 숫자인 경우  - Regression을 사용한다.
: : 보통 Regression은 **MSE(Mean Sqaured Error)**가 많이 쓰이게 된다.
: : MRC 문제에서도 MSE를 많이 사용한다. 정답 위치가 곧 숫자를 맞히는 문제이기 때문이다.
: : 두 문장의 문장 유사도 문제도 마찬가지
: : 추천 등의 문제에서 추천 정도 역시 숫자 맞히는 문제
<br><br>
: : 반면 Output이 Category인 경우 - Classification Loss를 사용한다.
: : 보통 Classification 문제는 **CE(Cross Entropy)**를 사용한다.
<br><br>


- 소제목2<br><br>
: :
: :


<h2>(2강)</h2>
- 강의 키워드<br><br>
: - 
: - 
: - 

- 소개<br><br>
: :
: : 

- 소제목1<br><br>
: :
: : 

- 소제목2<br><br>
: :
: :



<h2>Peer Session</h2>
- 1) 주제 1<br><br>
: : 
: : 
- 2) 주제 2<br><br>
: : 
: : 