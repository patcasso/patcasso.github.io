---
layout: single
title:  "확률론 기초 - 9강"
categories: boostcamp-math
sidebar:
  nav: "docs"
---

# 23/11/16 확률론 9강

<h2>9강- 기댓값, 지시확률변수와 선형성 (Expectation, Indicator Random Variables, Linearity)</h2>

- 학습목표
: - 확률분포를 해석하는 세 가지 접근방식을 이해하고 적용할 수 있고, 이항분포, 초기하분포를 이해한다. 

- 핵심 키워드
: - 누적분포함수(CDF)
: - 독립 확률변수
: - 기댓값(expectation)
: - 지시확률변수
: - 선형성(linearity)
: - 기하분포


- CDF(누적분포함수)<br><br>
: : <a href="https://ko.wikipedia.org/wiki/%EB%88%84%EC%A0%81_%EB%B6%84%ED%8F%AC_%ED%95%A8%EC%88%98">CDF</a> 란? $F(x) = P(X \leq x)$, as a function of real $x$<br><br>
<img src="../../images/231116 stats 9-1.png" width="200px"><br><br>
: $x$ axis : possible values (0, 1, 2, 3)
: : The value reaches 1 and stays there forever
: : If we want PMF, it's going to be jump sizes
: : PMF - they have to be non-negative and add up to 1
: : We can recover CDF from PMF just by summing things up.<br><br>
: Q) Find $P(1 < x \leq 3)$ using F.
: : $P(X \leq 1) + P(1 < X \leq3) = P(X \leq 3)$
: : => $P(1 < X \leq 3) = F(3) - F(1)$
: : It could be continuous, discrete, anything.
: : $P(a < X \leq b) = F(b) - F(a)$<br><br>
: <br><b>Properties of CDF</b><br><br>
: (1) Increasing 
: &emsp;(can have flat steps, but can't go down)
<br><br>
: (2) Right continuous
: &emsp;(Continuous from the right side)
<br><br>
: (3) $F(x) \to 0$ as $x \to - \infty$
: &emsp;$F(x) \to 1$ as $x \to  \infty$
<br><br>
: : This is "if and only if
: <br><b>Independence of r.v.s</b><br><br>
: : $X,Y$ are independent r.v.s, if $P(X \leq x, Y \leq y) = P(X \leq x) \times P(Y \leq y)$ for all $x, y$
: : In Discrete case,
: : PMF, $P(X = x, Y = y) = P(X=x) \times P(Y=y)$
: : The equation above won't work in continuous case, it just means $0 = 0$
- Averages (Means, Expected Values)<br><br>
: : How to calculate the average of r.v.s.
: : Variance, Standard Deviation, ... later
<br><br>
: : $1,2,3,4,5,6 \to \frac{1+2+3+4+5+6}{6} = 3.5$
: => $\frac{1}{n} \cdot \sum_{j=1}^{n}j = \frac{n+1}{2}$
: : Arithmetic series
<br><br>
: : $1,1,1,1,1,3,3,5$
: : Two ways
: 1) add, divide by 8 (Unweighted average)
: 2) Group 1s together, group 3s together, and 5 alone well
: : $\frac{5}{8} \cdot 1 + \frac{2}{8} \cdot 3 + \frac{1}{8} \cdot 5$
: : You can see them as 'Weighted Average', weighted by numbers of 1, 3, 5s
<br><br>
: <br><b>Average of a <u>discrete random variable X</u></b><br><br>
: : standard notation is to write $E(X)$ (E = Expected Value)
: : $E(X)= \sum_{x}x \cdot P(X=x)$
: : $x$ is value, $P(X=x)$ is PMF
: : Summed over $x$ with $P(X=x)>0$
<br><br>
<u>$X \sim Bern(p)$</u>
<br><br>
: $E(X) = 1 \cdot P(X=1) + 0 \cdot p(X=0) = p$
<br><br>
: X = 1, if A occurs
: X = 0, otherwise
: It's called "Indicator r.v."
<br><br>
: <u> $\therefore E(X) = P(A)$</u>
: : "Fundamental Bridge"
<br><br><br>
: <u>$X \sim Bin(n,p)$</u>
<br><br>
: $E(X) = \sum_{k=0}^{n}k \cdot \binom{n}{k} \cdot p^k \cdot q^{n-k}$
: &nbsp;&emsp;&emsp;&emsp;$= \sum_{k=0}^{n}n \cdot \binom{n-1}{k-1} \cdot p^k \cdot q^{n-k}$
: &nbsp;&emsp;&emsp;&emsp;$= np \cdot \sum_{k=1}^{n}\binom{n-1}{k-1} \cdot p^{k-1} \cdot q^{n-k}$
: &nbsp;&emsp;&emsp;&emsp;$= np \cdot \sum_{j=0}^{n-1}\binom{n-1}{j} \cdot p^{j} \cdot q^{n-1-j}$
: &nbsp;&emsp;&emsp;&emsp;&emsp;($j = k -1, k = j + 1$)
: &nbsp;&emsp;&emsp;&emsp;$=np$ <span style="color:red">(The latter part is just 1?)</span>
<br><br>
: <br><b>Linearity</b><br><br>
: : $E(X+Y) = E(X) + E(Y)$ (even if $X, Y$ are dependent)
: : $E(c \cdot X) = c \cdot E(X)$ (if $c$ is a constant)
<br><br>
: : Let's <u>Redo the $Binomial$</u> with linearity.
: : $X \sim Bin(n,p)$, we can think of it as sum of $n$ i.i.d. $Bern \sim (P)$s
: : Each of those $Bern \sim (P)$s have the expected value of $p$, and there's $n$ of them.
: $\therefore np$
: <br><b>Hypergeometric Distribution</b><br><br>
: : Ex. 5 card hand, X = (# of aces)
: : Let $Xj$ be indicator of $j$th card being an Ace ($1 \leq j \leq 5$)
: $E(X) = E(X_1 + \cdot\cdot\cdot + X_5) = E(X_1) +  \cdot  \cdot  \cdot  +E(X_5) = 5 \cdot E(X_1)$ (symmetry)
: : $5 \cdot P$(1st card is ace) = $5 \cdot \frac{4}{52} = \frac{5}{13}$&emsp; (even though $Xj$s are dependent)
: : This give expected value of any Hypergeometric
<br><br>
: <br><b>Geometric Distribution</b><br><br>
: $Geom(p)$ : independent $Bern(p)$ trials
: : count # failures before the first success
<br><br>
: Let $X \sim Geom(p), q=1-p$
<br><br>
: ex) FFFFFS
: : $P(X=5) = q^5 \cdot p$
<br><br>
: <u>PMF</u> 
<br><br>
$$ P(X=k) = q^k \cdot p,k \in \{0, 1, 2, ...\}$$
: : Valid since $\sum_{k=0}^{\infty}p \cdot q^k = p \cdot \frac {1}{1-q} = 1$
: : $\sum_{k=0}^{\infty}q^k$ 가 geometric series여서
<br><br>
: <u>$X \sim Geom(p)$</u>
<br><br>
: $E(X)$
: $= \sum_{k=0}^{\infty}k \cdot p \cdot q^k = p \cdot \sum_{k=0}^{\infty}k \cdot q^k $
: $= \frac{pq}{p^2} = \frac{q}{p}$
<br><br>
: $\sum_{k=0}^{\infty}q^k = \frac{1}{1-q}$
: $\sum_{k=1}^{\infty}k \cdot q^{k-1} = \frac{1}{(1-q)^2}$
: $\sum_{k=1}^{\infty}k \cdot q^{k} = \frac{q}{p^2}$
<br><br>
: <u>Story proof</u>
: : Let, $c = E(X)$
<br><br>
: $c = 0 \cdot p + (1+c) \cdot q$
: &emsp;$= q+c \cdot q$
: &emsp;$= \frac{q}{p}$