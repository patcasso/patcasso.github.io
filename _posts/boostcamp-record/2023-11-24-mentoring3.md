---
layout: single
title:  "(11/24) 멘토링 3"
categories: boostcamp-record
sidebar:
  nav: "docs"
---

<h2>멘토링 3 : 언어모델의 역사 요약</h2>
(정기영 멘토님)

1. GPT가 뭔데?<br><br>
: - 언어 모델의 정의: 이전 단어들로 다음에 올 단어(token)를 예상하는 모델<br><br>
: 1) N-gram<br><br>
: : 처음에는 책에 등장하는 단어의 빈도를 확률 계산
: : N-gram (확률 = 이전 N 단어 이후 등장 빈도)
: : 굉장히 오래된 아이디어이지만, 현재 현업에서도 많이 쓰인다
<br><br>
: 2) 신경망 계열 - RNN<br><br>
: : 이전 단어들을 학습하여 다음 단어를 예측하는 딥러닝 모델
: : 새로운 단어가 계속 추가될수록, 앞의 단어의 영향력이 떨어지게 학습됨(= vanishing gradient)
<br><br>
: 3) Transformer - GPT<br><br>
: : 이전 단어들 중 더 <u>중요한</u> 단어들을 파악 = <u>Attention</u>
: : Attention을 활용하여 다음에 올 단어들의 <u>확률</u>을 계산
: : 병렬화 학습이 가능해서 <u>초대형 모델</u>을 만들 수 있다
: : 인코딩은 단어를 벡터화 시키는 것, 디코딩은 벡터로 다시 문장을 예측해서 구현하는 것
: : 인코딩 부분을 BERT라고 하고, 디코딩 하는 부분을 GPT 라고 하는 것.
: : BERT는 언어 모델이라고 부르기는 어렵고, 단어를 기계가 이해할 수 있도록 토큰화 시키는 역할
: : GPT가 진정으로 다음 토큰을 예측하는 언어 모델인 것이다!
: : Attention 외에 RNN보다 좋은 점은, RNN은 하나씩 feeding하면서 학습해야 하는데, GPT는 통째로 넣고 학습을 돌릴 수 있어서 학습이 굉장히 수월해진다. => 초대형 모델(LLM)을 만들 수 있게 되었다.

2. LLM의 시대<br><br>
: : GPT-1, 2, 3 로 넘어가면서 parameter 수가 10배 이상씩 증가
: : GPT-3.5에서 RLHF(reinforcement learning with human feedback), 즉, 사람의 피드백을 추가해 나온 것이 ChatGPT에서 사용하는 3.5 모델
: : 또 데이터를 8, 9배 가량 늘려서 학습해서 나온 것이 GPT-4이다.
<br><br>
: : GPT 모델을 크게 만드는 이유 - 기존의 Fine-tuning한 하나의 task만이 아닌(ex. 번역), <u>모든 자연어 task</u>를 수행 가능한다는 것
: : 다음 토큰의 정확한 <u>예측</u> + <u>프롬프팅</u>(zero-shot, few shot) = 모든 자연어 task 수행 가능

3. ChatGPT<br><br>
: : 'GPT'는 언어 모델을 학습하는 모델의 이름일 뿐이다.
: : GPT-1, 2, 3은 메커니즘을 이야기하는 것이 아니라 본인들의 데이터로 학습을 완료해 제공하는 Pre-trained 된 언어 모델을 서비스하는 것이다.
: : GPT-3 + (대화형 인터페이스 / 대화를 통한 지속적 학습(RLHF) / 안정성 및 윤리성) = ChatGPT
<br><br>
: <br><b>대화형 인터페이스</b><br><br>
: : <u>System</u>
: : GPT에게 주는 전반적인 지시사항
: : 기술적으로 대화에서 처리해야 할 task를 명시
<br><br>
: : <u>User</u>
: : 사용자의 실제 입력
: : 질문, 명령, 대화 등 모든 내용이 가능
<br><br>
: : <u>Assistant</u>
: : User 인풋에 대한 대답
: : 사용자의 요청에 대응하는 내용
<br><br>
4. Python에서 GPT를 활용하기
: : 실습 코드 참조
: : <span style="color:blue">숙제1) 내가 생각해낸 태스크 하나씩을 GPT 프롬프트로 코드화 시켜서 제작해오기 (바로 돌아가는 하나의 함수 형태로)- 자연어 태스크 아무거나 해도 됨(다음주까지)</span>
: : <span style="color:red">=> 대본 정리 시켜보자!</span>
<br><br>
: <br><b>Q&A</b><br><br>
: : {분류된 감정} 의 형태로 프롬프팅을 준 이유 : 그냥 사람들이 활용하는 형태로 똑같이 활용하기 때문에. 즉, 코드에서 fstring 안에서 변수에 {name} 식으로 주는 방식을 그대로 따라한 것
: : Latency 차이는 모델마다 있을 수 있다. (전세계 사람들의 서버 활용량 등.. 주로 '생성되는' 토큰이 길면 오래 걸린다(인풋 토큰 수와 상관 없이))
: : .csv, .xlsx 등 콤마나 개행문자 등의 delimiter들로 구분된 데이터 형태를 넣어줘도 알아서 잘 인식하고 처리한다고 한다. 해보자.